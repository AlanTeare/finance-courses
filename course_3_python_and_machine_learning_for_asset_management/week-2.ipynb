{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "\n",
    "\n",
    "import cvxpy as cp\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from scipy.optimize import minimize\n",
    "from pandas_datareader import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import factor_model_lib as fm\n",
    "sys.path.append(\"../\")\n",
    "import edhec_risk_kit as erk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using seaborn style (type plt.style.available to see available styles)\n",
    "plt.style.use(\"seaborn-dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brief summary of week 1 (questions and home points)\n",
    "\n",
    "## Introduction to Machine Learning\n",
    "\n",
    "**QUESTION: What distinguishes supervised learning from unsupervised learning? Multiple responses possible.**\n",
    "1. Supervised learning requires labeled data to properly classify objects, whereas unsupervised learning identifies interesting patterns in data – without label\n",
    "2. Most successful applications of machine learning have occurred in supervised learning\n",
    "3. Supervised learning requires a human to watch over the algorithm to be sure that it’s  working properly.\n",
    "\n",
    "**ANSWER: 1,2.** Supervised learning includes classification such as identifying the name of a song or the numbers on a handwritten zip-code. The success of these schemes depends upon several items: a large set of labeled data. I call this amount of data needed for a successful application: *adequate data*. Second, in most cases, there is the need for a type of stability. \n",
    "For example, we assume that the zip-code IDs remains the digits 0-9. \n",
    "\n",
    "Over the past decade, most successes in machine learning have occurred in the area of supervised learning (mostly classification). More recently, there have been breakthroughs in games such as Chess, Shogi, and Go, whereby the DeepMind team \n",
    "at Google in London have created the world best software for these problem. This domain fits under **reinforcement learning**.\n",
    "\n",
    "**QUESTION: What are the main differences between traditional statistical methods and modern non-parametric methods? Multiple responses possible.**\n",
    "1. Few assumptions needed for non-parametric methods\n",
    "2. Traditional statistical methods rely on assumptions such as normal distributions for the random variables\n",
    "3. Traditional statistics depend upon massive data\n",
    "\n",
    "**ANSWER: 1,2**. The area of classical statistical analysis grew up with a host of assumptions. The most obvious ones occur \n",
    "in linear regression: linearity of explanatory and outcome variables, additivity, and relative independence \n",
    "of the explanatory variables. Massive research took place in the 1950s and 1960s to overcome some of these assumptions, \n",
    "such as adding nonlinear transformations, and addressing other loss functions such as absolute value |L1|.  \n",
    "These extensions had a minor impact on practice, partially due to the focus on theoretical properties of the techniques. \n",
    "Recall the long list of tests to *prove* statistical significance. The area of non-parametric methods began with \n",
    "the emergence of data collection at much higher frequency and across domains. These techniques led to modern \n",
    "machine learning algorithms and improved testing methodologies. In addition, statisticians (and other data scientists) \n",
    "began to recognize that stochastic optimization plays a critical role in the success of machine learning. \n",
    "In particular, increased computational capability, merged with large data and incentives for improving classification, \n",
    "has resulted in practical successes. These successes have surprised many expert observers over the past decade. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Financial Applications\n",
    "\n",
    "**QUESTION: What are a few future applications of the FinTech revolution?**\n",
    "1. Robo-advisors will replace human investment advisors\n",
    "2. FinTech promises to bring loans and mortgages to individuals without long approval periods\n",
    "3. Machine learning algorithms will find the best performing stock and thereby eliminate investment professional\n",
    "4. Machine learning will be able to decide upon the best home location to satisfy our needs\n",
    "\n",
    "**ANSWER: 2**. The use of machine learning to issue bonds and mortgages is confirmed by reference to the efforts by \n",
    "Ant Financial in China – the MyBank app. Here, loans are issues with any formal support from the \n",
    "Ant Financial team and without reference to the massive amounts of research in this domain.\n",
    "\n",
    "Some HOME POINTS:\n",
    "- Financial Applications are often more complex than direct classification, e.g., due to privacy and ethical issues \n",
    "- Machine Learning algorithms can be difficult to interpret \n",
    "- Feature selection very important "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "\n",
    "**QUESTION: Which of the following are successful applications of supervised learning? Multiple responses possible.**\n",
    "1. Identify objects in front of an auto or truck\n",
    "2. Computer driven loans for individuals\n",
    "3. Fraud detection for credit cards\n",
    "\n",
    "**ANSWER: all of them.** The successes in supervised learning are arriving at an accelerating rate. Outside of finance,  we can readily identify the name of a song by an app listening to a few bars, or we can give a name to a \n",
    "bird or tree without fail. Likewise, zip-codes are read by automated supervised learning algorithms, \n",
    "at a lower error rate than humans. Visual object identification has gained in accuracy as well, and \n",
    "these classification algorithms are a critical element in automated vehicles. \n",
    "In the area of finance and banking, FinTech firms such as Ant Financial are able to issue \n",
    "loans by means of machine learning, without the need for traditional bankers or brick and mortar \n",
    "bank branches. And fraud detection has been improved. **There is still much to be done in the domain of decision making under uncertainty.**\n",
    "\n",
    "\n",
    "**QUESTION: What are the primary assumptions of supervised learning? Multiple responses possible.**\n",
    "1. There is adequate data possessing labels\n",
    "2. The underlying application has stability so that the data is representative\n",
    "3. The labels indicate correct classification\n",
    "4. The classification problem requires linearity\n",
    "\n",
    "**ANSWER: 1,2,3**. The nature of supervised learning requires data with the correct classification, called labels. \n",
    "The amount of data must be “adequate” so that the machine learning algorithm is able to identify \n",
    "the characteristics for future out-of-sample evaluation. \n",
    "In addition, there must be enough stability over time. \n",
    "\n",
    "Some HOME POINTS:\n",
    "- Machine Learning operates on a large number of features. Perhaps more systematic than humans. \n",
    "- Humans apply intuition and vast experience. \n",
    "- Computers apply multiple algorithms with a large number of features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First algorithms\n",
    "**QUESTION: How does the train-and-test approach improve accuracy? Multiple responses possible**\n",
    "1. Provides out-of-sample evidence and thereby reduces overfitting\n",
    "2. Allows for evaluation of performance ex post\n",
    "3. Refines the information content of historical data\n",
    "\n",
    "**ANSWER: 1,3**. Traditional statistical methods rely on a large number of assumptions in order to provide \n",
    "evidence of good statistical properties. On the other hand, machine learning algorithms \n",
    "render fewer assumptions than traditional methods, and thereby there is a greater need \n",
    "for out-of-sample analysis. The train-and-test approach, in conjunction with cross validation, fits this philosophy. \n",
    "\n",
    "Some HOME POINTS:\n",
    "- Adequate data must be available so that results can be generalised.\n",
    "- Data must relatively stable, changes in the data cannot occur at high frequency. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highlights of best practice and challenges ahead\n",
    "**QUESTION: What is the motivation for employing an ensemble forecasting framework?**\n",
    "1. The forecasting problem can be posed as a linear regression model\n",
    "2. The application requires linearity\n",
    "3. Ensemble forecasts are superior to a single forecasting model when the aggregation of weak classifiers is better than the forecast of a single strong classifier\n",
    "\n",
    "**ANSWER: 3**. There are many examples in which an ensemble forecast is more reliable than the forecast \n",
    "from a single model.  An example is the forecast of recessions in the U.S. over the last 20 years. \n",
    "The Blue Chip economists projections were better able to forecast a recession than the \n",
    "leading econometric forecasting system\n",
    "\n",
    "**QUESTION: What are the advantages of the train-and-test procedures? Multiple responses possible.**\n",
    "1. Helps evaluate the model’s capability via out of sample testing\n",
    "2. Reduces the chances of overfitting\n",
    "3. Provides a full proof approach for classification\n",
    "4. Indicates readiness for decision making\n",
    "\n",
    "**ANSWER: 1,2**. The traditional statistical methods such as linear regression and econometrics made a \n",
    "number of assumptions about model structure and employed as much historical data as possible. \n",
    "Machine learning, on the other hand, employs the data without many assumptions about \n",
    "model structure. This approach requires much more data than earlier methods, but it \n",
    "provides more reliable algorithms for classification in many situations.\n",
    "The train-and-test procedures are employed to calculate the (hyper-parameters) of a model \n",
    "via out-of-sample data and to reduce the chances of overfitting.  As we have mentioned, \n",
    "a model that fits the data perfectly in-sample is often unable to do well with out of sample data. \n",
    "Thus, the train-and-test procedure is helpful in reducing overfitting. \n",
    "\n",
    "\n",
    "\n",
    "**QUESTION: What are potential and actual successes of reinforcement learning? Multiple responses possible**\n",
    "1. The most powerful game playing systems in the world for chess, shogi, and go (AlphaZero)\n",
    "2. Automated medical diagnosis and treatment\n",
    "3. Online poker playing and associated betting strategies\n",
    "4. Identifying products for customers on the Amazon website\n",
    "\n",
    "**ANSWER: 1,3,4**. The area of reinforcement learning has gained much credibility and renown since the fast and \n",
    "powerful successes of the DeepMind team at Google with their software systems that \n",
    "created the world’s most powerful systems for playing chess, shogi, and go. This remarkable \n",
    "system requires no domain specific information about the game.  Instead, it simply “watches” \n",
    "each of these gains over a carefully curated set of experiments.  \n",
    "The product selection problem has similar characteristics in terms of its potential application \n",
    "of reinforcement learning. However, this area is much less structured that zero-sum games. \n",
    "And accordingly, there is controversy about the degree of success of **reinforcement learning**.\n",
    "\n",
    "\n",
    "Some HOME POINTS:\n",
    "- Train and test process\n",
    "- Ensamble models: combine a set of weak classifier into a strong classifier (boosting); then take the average of classifiers (**Wisdom of the crowd**) -> more robust classification \n",
    "- Shrinkage methods "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WEEK 2\n",
    "\n",
    "Below we briefly recall **factor models** (**see week 1 and week 2 of course 2**).\n",
    "\n",
    "## Factor models\n",
    "A **factor** is a variable that influences the **returns of assets**. It represents a **commonality** \n",
    "in the returns, i.e., something outside the individual asset, and normally, **an exposure to some factor risk** over the long run **yields a reward** (the risk premium).\n",
    "\n",
    "In general, a **(multi)-factor model** with $K$ factors states that the \n",
    "**excessive return** of an asset $i$ satisfies:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t}  = \\alpha_i + \\beta_1^i f^{e}_1 +\\dots +\\beta_K^i f^{e}_K + \\varepsilon_{i,t}, \n",
    "$$\n",
    "where $\\{\\beta_j^i\\}_{j=1,\\dots,K}$ and $\\alpha_i$ are some real coefficients to be estimated, $\\varepsilon_{i,t}$ are idiosyncratic (uncorrelated) errors, and $\\{f_j\\}_{i=j,\\dots,K}$ are the **factor premia** which are the **returns that we get in exchange for exposing ourselves to the factors** (in particular $f^{e}_j$ denotes the excess return of the factor). \n",
    "\n",
    "We will call the betas coefficients as the **factor loadings**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Single Factor model\n",
    "We recall that the simplest factor model is the Sharpe's single-factor **Market Model** in which the only factor used is the excess return of the market $f^e_t = r_{m,t} - r_{f,t}$:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t} = \\alpha_i + \\beta^i (r_{m,t} - r_{f,t}) + \\varepsilon_{i,t}.\n",
    "$$\n",
    "In particular we recall that the **Capital Asset Pricing Model (CAPM)** is the model that predicts $\\alpha_i=0$:\n",
    "$$\n",
    "r_i^e := r_{i,t} - r_{f,t} = \\beta^i (r_{m,t} - r_{f,t}) + \\varepsilon_{i,t},\n",
    "$$\n",
    "and in which:\n",
    "$$\n",
    "\\beta_i := \\frac{\\text{Cov}(r_i,r_m)}{\\text{Var}(r_m)},\n",
    "$$\n",
    "denotes the sensitivity of the asset with respect to the market.\n",
    "\n",
    "\n",
    "In the risk analysis, we notice that when using the CAPM, we can obtain an expression for the variance of the return of asset $i$ in terms of the variance of the market. That is, if we take tha variance on both sides of the equation above:\n",
    "$$\n",
    "(\\sigma_i^e)^2 = \\beta_i^2 (\\sigma_m^e)^2 + \\sigma^2_{\\varepsilon_i},\n",
    "$$\n",
    "and this allows us to classify the risk between **systematic risk $(\\sigma_m^e)$** \n",
    "on the one hand and **specific risks $\\sigma_{\\varepsilon_i}$** on the other hand.\n",
    "\n",
    "Furthermore, we can alos define the $R^2$ metrics defined as:\n",
    "$$\n",
    "R^2 := \\frac{ \\beta_i^2 (\\sigma_m^e)^2 }{(\\sigma_i^e)^2}, \n",
    "$$\n",
    "which is **the part of the variance explained by the factor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fama-French Model\n",
    "\n",
    "The **Fama-French model** is a **three-factor** model which enhance the CAPM (one-factor model). The three factors are:\n",
    "- **Market Factor**: the market risk (i.e., as in the CAPM),\n",
    "- **Size Factor**: the outperformance of **small versus big** companies,\n",
    "- **Value Factor**: the outperformance of **high book/market versus small book/market** companies.\n",
    "\n",
    "What Fama and French did was to take the entire universe of stocks an put them into ten buckets (**deciles**). They sorted such deciles in two ways. \n",
    "\n",
    "A first sorting was done according to the **size**, i.e., the **market capitalization**, \n",
    "and then they compared the performance of the bottom $10\\%$ companies versus the top $10\\%$ companies according to the size.\n",
    "\n",
    "The second sorting was done according to the **book-to-market ratios** (B/P ratio), and then they did the same, i.e., they looked at \n",
    "the performance of the bottom $10\\%$ companies (Growth Stocks) versus the top $10\\%$ companies (Value Stocks). \n",
    "\n",
    "Fama and French observed that the classes of stocks that have tended to do better than the market as a whole have been \n",
    "(i) the **small caps** (bottom decile w.r.t sizes) and (ii) the **Value Stocks** (top decile w.r.t. B/P ratios). \n",
    "Hence, they introduced the **size factor** and the **value factor** in addition to the **market factor** \n",
    "of simple CAPM and enhance the model ($1993$): \n",
    "$$\n",
    "\\mathbb{E}[r_i] - r_f = \n",
    "\\beta_{i,\\text{MKT}}\\mathbb{E}[r_m - r_f] + \\beta_{i,\\text{SMB}}\\mathbb{E}[\\text{SMB}] + \\beta_{i,\\text{HMS}}\\mathbb{E}[\\text{HMS}],   \n",
    "$$\n",
    "where:\n",
    "- $\\beta_{i,\\text{MKT}}$ is the same $\\beta$ of the CAPM (we stress the dependence on the **market**), \n",
    "- $\\text{SMB}$ means **Small (Size) Minus Big (Size)** stocks, \n",
    "- $\\text{HML}$ means **High (B/P ratio) Minus Low (B/P ratio)** stocks.\n",
    "\n",
    "It is remarkable the fact that **high book-to-price stocks (i.e., Value stocks)**, **small-cap**, and **past winners** stocks \n",
    "have been found to earn a higher return (that is, they have been found to outperform **low book-to-price (Growth)**, **large-cap**, and \n",
    "**past losers** stocks, respectively)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Factors\n",
    "In addition to **market**, **value** and **size** factors, the **Momentum Factor** has been also very often used as a meaningful, explanatory variable to try and explain differences in expected return. \n",
    "\n",
    "The **Momentum factor** is defined as the **difference in performance between the past winners and the past losers**. In particular, the momentum can be seen as an attribute of the asset. \n",
    "We can think about the asset, on a given sample period, as being a past winner or a past loser and this would tend to explain some persistence in performance because past winners tend to outperform past losers. \n",
    "\n",
    "Literature has also looked at other factors, including the **Low Volatility factor**, distinguishing the low volatility assets from the high volatility assets. In this case, we found that **low volatility assets tend to outperform high volatility assets** even though they are less risky. \n",
    "\n",
    "There is also a **Liquidity Factor**. Less liquid assets tend to have a higher risk premia associated to them compared to higher liquidity stocks, as expected. \n",
    "\n",
    "Another last factor can be the **Quality Factor**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions on factors \n",
    "\n",
    "Let us consider tha case of a simple two-factors model ($K=2$): \n",
    "$$\n",
    "r_i^e := r_i - r_f =  \\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i\n",
    "\\quad \\forall\\;i=1,\\dots,N.\n",
    "$$\n",
    "\n",
    "Now, the variance of the asset's excess return is given by, for all $i$: \n",
    "$$\n",
    "c_{ii}^2 = (\\sigma_i^e)^2 := \\text{Var}\\left(\\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i\\right) \n",
    "= (\\beta_1^i)^2 \\sigma_{f_1}^2 + (\\beta_2^i)^2 \\sigma_{f_2}^2 + 2\\beta_1^i \\beta_2^i\\text{Cov}(f_1,f_2) + \\sigma_{\\varepsilon_i}^2, \n",
    "$$\n",
    "where we have assumed that the **covariances between factors and errors are zero**. \n",
    "\n",
    "The covariances are then:\n",
    "$$\n",
    "c_{ij} = \\text{Cov}\\left(r_i^e,r_j^e\\right) \n",
    "= \\text{Cov}\\left(\\beta_1^i f_1 + \\beta_2^i f_2 + \\varepsilon_i, \\beta_1^j f_1 + \\beta_2^j f_2 + \\varepsilon_j\\right)\n",
    "= \\beta_1^i \\beta_1^j \\sigma_{f_1}^2 \n",
    "+ \\beta_2^i \\beta_2^j \\sigma_{f_2}^2 \n",
    "+ \\left(\\beta_1^i \\beta_2^j + \\beta_2^i \\beta_1^j\\right) \\text{Cov}(f_1,f_2) + \\text{Cov}(\\varepsilon_i,\\varepsilon_j).\n",
    "$$\n",
    "\n",
    "In a general multi-factor model (with $K$ factors), the variances and covariances are then given by:\n",
    "\\begin{align}\n",
    "c_{ii}^2 &= \\sum_{k=1}^K \\beta_k^i\\sigma_{f_k}^2 + \\sum_{k\\neq n}\\beta_k^i\\beta_n^i \\text{Cov}(f_k,f_n) + \\sigma_{\\varepsilon_i}^2, \\\\\n",
    "c_{ij}   &= \\sum_{k=1}^K \\beta_k^i\\beta_k^j\\sigma_{f_k}^2 + \\sum_{k\\neq n} \\beta_k^i\\beta_n^j \\text{Cov}(f_k,f_n)  \n",
    "+ \\text{Cov}(\\varepsilon_i,\\varepsilon_j) \n",
    "\\quad\\text{for $i\\neq j$}.\n",
    "\\end{align}\n",
    "\n",
    "Now, two things that we should try to do are (i) try to **look for uncorrelated factors**, i.e., $\\text{Cov}(f_k,f_n)=0$, for $k\\neq n$,  \n",
    "and (ii) assume that **errors are uncorrelated**, i.e., $\\text{Cov}(\\varepsilon_i,\\varepsilon_j)=0$, for $i\\neq j$. \n",
    "If a few factors can completely capture the cross-sectional risks, the number of parameters in covariance matrix estimation can be significantly reduced. In particular, the equations above are simplified:\n",
    "\\begin{align}\n",
    "c_{ii}^2 &= \\sum_{k=1}^K \\beta_k^i\\sigma_{f_k}^2  + \\sigma_{\\varepsilon_i}^2, \\\\\n",
    "c_{ij}   &= \\sum_{k=1}^K \\beta_k^i\\beta_k^j\\sigma_{f_k}^2\n",
    "\\quad\\text{for $i\\neq j$}.\n",
    "\\end{align}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression and Penalty Methods\n",
    "When using a factor model, all is about estimating parameters betas and alphas. \n",
    "Normally, we can conduct **traditional regressions**, where we minimize some error between the return of the asset that we are \n",
    "looking at and the loadings of the factors on that asset.\n",
    "\n",
    "### Classic Least-Squared fit (Ordinary Least-Squared OLS)\n",
    "\n",
    "In this context, we have a $n\\times 1$ vector $\\mathbf{y}$ which is the excess return of the asset under consideration and a $n\\times K$ \n",
    "matrix $X$ which represent our data, i.e., the excess return of the $K$ factors we have chosen. Hence we have to minimize:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N}||\\mathbf{y} - X\\mathbf{\\beta}||_2^2 = \n",
    "\\frac{1}{2N}\\sum_{i=1}^n \\left(y_i  - X_i\\cdot\\mathbf{\\beta}  \\right)^2, \n",
    "$$\n",
    "where $\\mathbf{\\beta}=(\\beta_1,\\dots,\\beta_K, \\alpha)^T$ is the vector of betas and the intercept alpha coefficients, \n",
    "and $X_i$ denotes the $i$-th row of the matrix $X$. \n",
    "The betas give us the best solution fitting of the assets to a linear relationship between the explanatory variables (the factors) \n",
    "and the dependent variable (the return of the asset). \n",
    "\n",
    "For such a minimization problem we can find the analytical expression for coefficients betas and alpha. The solution is given by \n",
    "$$\n",
    "\\beta^{\\text{OLS}} = (X^T X)^{-1} X^T \\mathbf{y}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Ridge methods ($L^2$ penalization)\n",
    "\n",
    "Traditional regression methods are enhanced and made more robust by addign **penalty terms**. In particular, betas values would be much too high or low if the expalantory variables (the factors) had moderate-to-hight correlation. \n",
    "\n",
    "Then we can modify the minimization problem above by adding an extra term which at the end of the day simply \n",
    "**shrinks the optimal betas values**:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta}||^2_2 + \\lambda||\\beta||_2^2  \\bigr)\n",
    "$$\n",
    "which is equivalent on solving the classic least-squared fit problem with a constraint on the betas coefficients. This method is called **$L^2$ penalization method or Ridge regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Lasso methods ($L^1$ penalization)\n",
    "\n",
    "A second modification to the first minimization problem is adding an extra term which, as in the Ridge regression, \n",
    "simply **shrinks the optimal betas values** and increase sparsity of the coefficient:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda||\\beta||_1  \\bigr)\n",
    "$$\n",
    "which is equivalent on solving the classic least-squared fit problem with a constraint on the betas coefficients. This method is called **$L^1$ penalization method or Lasso regression**.\n",
    "\n",
    "Lasso regression results in a sparser solution than Ridge regression (i.e., fewer coefficients with non-zero values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Penalty method: Elastic Net\n",
    "\n",
    "A third modification of the first minimization problem is putting together both the Lasso and the Ridge penalizations, i.e., we add \n",
    "adding two extra terms for shrinking the optimal betas values and increase sparsity of the coefficient:\n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda_1||\\beta||_1 + \\lambda_2||\\beta||^2_2  \\bigr).\n",
    "$$\n",
    "This method is called the **Elastic Net regression**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Subset Regression \n",
    "\n",
    "Penalized regressions are not the only type of regression we can run. We can also run constrained regressions. \n",
    "Formally, we define an intuitive constrained regression called the **Best Subset Regression** which attempts to find the linear model subject to the constraint that only $x$ factor loadings can be nonzero (in this case, $x$ is an integer that the user defines).\n",
    "\n",
    "The best subset regression is defined as follows. \n",
    "Let $L$ be the number of variables considered, i.e., the explanatory variables of the model (the factors) and let $N$ be the maximum number of variables allowed in the subset. \n",
    "Also let $\\textbf{z}$ be a $L\\times 1$ vector of **binary variables** and let $M$ be a very \n",
    "large number. \n",
    "Then: \n",
    "\\begin{equation*} \n",
    "    {\\hat{\\beta}}^{\\text{Best Subset}} = \\text{argmin}\\left\\{ ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 \\right\\}\n",
    "\\end{equation*}\n",
    "subject to:\n",
    "\\begin{cases}\n",
    "\\sum_{i=1}^{L} z_i &\\leq N,  \\\\\n",
    "Mz + \\beta & \\geq 0,         \\\\\n",
    "\\beta  &\\leq Mz,             \\\\\n",
    "\\text{$\\mathbf{z}$ is binary}\n",
    "\\end{cases}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation\n",
    "\n",
    "The **Cross validation** is a Machine Learning approach for calculating the parameter in a statistical estimation task. \n",
    "Rather than fitting a model to all of the available data, **the approach “sets aside” subsets of the data for a validation phase** and repeat the process a certain number of times (e.g. 10 times). Then it averages the results obtained.\n",
    "\n",
    "For the purpose of factor investing, we add a penalty term to shrink the beta estimates, the factor loadings in the regression model \n",
    "(e.g., by using Ridge or Lasso regression). In addition, we add a penalty parameter that determines the best degree of shrinkage. \n",
    "This hyper parameter is calculated by identifying the value with the lowest out-of-sample error. \n",
    "Thus, **cross validation reduces the chances of overfitting**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_to_data_folder():\n",
    "    return \"/Users/mariacristinasampaolo/Documents/python/git-tracked/finance-courses/course_3_python_and_machine_learning_for_asset_management/data/\" \n",
    "\n",
    "def get_factors_and_assets():\n",
    "    '''\n",
    "    Returns a set of factors (from 1985-01 to 2018-09)\n",
    "    '''\n",
    "    filepath = path_to_data_folder() + \"Data_Oct2018_v2.csv\"\n",
    "    factors = pd.read_csv(filepath, index_col=0, parse_dates=True)\n",
    "    factors.index = pd.to_datetime(factors.index, format=\"%Y%m\").to_period(\"M\") #.to_period(\"M\") forces the index to be monthly period...\n",
    "    return factors\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "# Linear regression\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "def linear_regression_sk(dep_var, exp_vars):\n",
    "    '''\n",
    "    Runs a linear regression to decompose the dependent variable into the explanatory variables \n",
    "    using scikit-learn LinearRegression() method\n",
    "    It returns the object lm:\n",
    "    - lm.coef_ to print the betas\n",
    "    - lm.intercept to print the intercept alpha\n",
    "    Note that exp.vars can be both a pd.DataFrame a np.array.\n",
    "    '''            \n",
    "    lm = LinearRegression(fit_intercept=True)\n",
    "    return lm.fit(exp_vars, dep_var)\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "# Lasso regression\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "def lasso_regression_sk(dep_var, exp_vars, lambdapar=1):\n",
    "    '''\n",
    "    Runs a linear regression to decompose the dependent variable into the explanatory variables \n",
    "    using scikit-learn Lasso() method.\n",
    "    It returns the object lm:\n",
    "    - lm.coef_ to print the betas\n",
    "    - lm.intercept to print the intercept alpha\n",
    "    Note that exp.vars can be both a pd.DataFrame a np.array.\n",
    "    '''            \n",
    "    lm = Lasso(alpha=lambdapar/(2*dep_var.shape[0]), fit_intercept=True)\n",
    "    return lm.fit(exp_vars, dep_var)\n",
    "\n",
    "def cross_val_lasso_regression(dep_var, exp_vars, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=None):\n",
    "    '''\n",
    "    Gridsearch Cross-Validation of Lasso regression.\n",
    "    Recall that the best lambda is given by: best_lambda = best_alpha*2*exp_vars.shape[0], \n",
    "    where best_alpha = gsCV.best_params_[\"alpha\"]\n",
    "    '''\n",
    "    # setup the estimator \n",
    "    if rs is None: \n",
    "        lasso_test = Lasso(fit_intercept=True)\n",
    "    else:\n",
    "        lasso_test = Lasso(random_state=rs, fit_intercept=True)\n",
    "    \n",
    "    # setup parameters\n",
    "    alpha_max = lambda_max / (2*exp_vars.shape[0])\n",
    "    alphas = np.linspace(1e-6, alpha_max, n_lambdas)\n",
    "    alphas = {'alpha': alphas}\n",
    "\n",
    "    # Grid Search Cross Validation\n",
    "    gsCV = GridSearchCV(estimator=lasso_test, param_grid=alphas, cv=n_folds, refit=True)\n",
    "    gsCV.fit(exp_vars, dep_var)\n",
    "    \n",
    "    return gsCV\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "# Ridge regression\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "def ridge_regression_sk(dep_var, exp_vars, lambdapar=1):\n",
    "    '''\n",
    "    Runs a linear regression to decompose the dependent variable into the explanatory variables \n",
    "    using scikit-learn Ridge() method.\n",
    "    It returns the object lm:\n",
    "    - lm.coef_ to print the betas\n",
    "    - lm.intercept to print the intercept alpha\n",
    "    Note that exp.vars can be both a pd.DataFrame a np.array.\n",
    "    '''            \n",
    "    lm = Ridge(alpha=lambdapar, fit_intercept=True)\n",
    "    return lm.fit(exp_vars, dep_var)\n",
    "\n",
    "def cross_val_ridge_regression(dep_var, exp_vars, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=None):\n",
    "    '''\n",
    "    Gridsearch Cross-Validation of Ridge regression.\n",
    "    Recall that the best lambda is given by: best_lambda = best_alpha*2*exp_vars.shape[0], \n",
    "    where best_alpha = gsCV.best_params_[\"alpha\"]\n",
    "    '''\n",
    "    # setup the estimator \n",
    "    if rs is None: \n",
    "        ridge_test = Ridge(fit_intercept=True)\n",
    "    else:\n",
    "        ridge_test = Ridge(random_state=rs, fit_intercept=True)\n",
    "    \n",
    "    # setup parameters\n",
    "    alpha_max = lambda_max\n",
    "    alphas = np.linspace(1e-6, alpha_max, n_lambdas)\n",
    "    alphas = {'alpha': alphas}\n",
    "\n",
    "    # Grid Search Cross Validation\n",
    "    gsCV = GridSearchCV(estimator=ridge_test, param_grid=alphas, cv=n_folds, refit=True)\n",
    "    gsCV.fit(exp_vars, dep_var)\n",
    "    \n",
    "    return gsCV\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "# Elastic Net regression\n",
    "# ----------------------------------------------------------------------------------------------------------------------------\n",
    "def elasticnet_regression_sk(dep_var, exp_vars, lambdapar=0.25, l1_ratio=0.5):\n",
    "    '''\n",
    "    Runs a linear regression to decompose the dependent variable into the explanatory variables \n",
    "    using scikit-learn ElasticNet() method.\n",
    "    It returns the object lm:\n",
    "    - lm.coef_ to print the betas\n",
    "    - lm.intercept to print the intercept alpha\n",
    "    Note that exp.vars can be both a pd.DataFrame a np.array.\n",
    "    '''            \n",
    "    alpha = lambdapar / (2*exp_vars.shape[0])\n",
    "    lm = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, fit_intercept=True)\n",
    "    return lm.fit(exp_vars, dep_var)\n",
    "\n",
    "def cross_val_elasticnet_regression(dep_var, exp_vars, lambda_max=0.25, n_lambdas=50, l1_ratio_max=0.99, n_l1ratio=50, n_folds=10, rs=None):\n",
    "    '''\n",
    "    Gridsearch Cross-Validation of Elastic Net regression.\n",
    "    Recall that the best lambda_1 and best lambda_2 are given by:\n",
    "    - best lambda_1 = best_alpha*2*exp_vars.shape[0]*best_L1ratio      is given by: best_lambda = best_alpha*2*exp_vars.shape[0], \n",
    "    - best lambda_2 = best_alpha*exp_vars.shape[0]*(1-best_L1ratio)  \n",
    "    where:\n",
    "      best_alpha = gsCV.best_params_[\"alpha\"]\n",
    "      best_L1ratio = gsCV.best_params_[\"l1_ratio\"]\n",
    "    '''\n",
    "    # setup the estimator \n",
    "    if rs is None: \n",
    "        elastic_net_test = ElasticNet(fit_intercept=True)\n",
    "    else:\n",
    "        elastic_net_test = ElasticNet(random_state=rs, fit_intercept=True)\n",
    "    \n",
    "    # setup parameters\n",
    "    alpha_max = lambda_max / (2*exp_vars.shape[0])\n",
    "    alphas    = np.linspace(1e-6, alpha_max, n_lambdas)\n",
    "    l1_ratios = np.linspace(1e-6, l1_ratio_max, n_l1ratio)\n",
    "    params    = {'alpha': alphas, 'l1_ratio': l1_ratios}\n",
    "\n",
    "    # Grid Search Cross Validation\n",
    "    gsCV = GridSearchCV(estimator=elastic_net_test, param_grid=params, cv=n_folds, refit=True)\n",
    "    gsCV.fit(exp_vars, dep_var)\n",
    "    \n",
    "    return gsCV \n",
    "\n",
    "def recover_regression_bestpar_from_gsCV(gsCV, data, reg_type):\n",
    "    '''\n",
    "    Return the best parameter found by the gridsearch cross-validation process \n",
    "    for the given input gsCV model that can be of reg_type:\n",
    "    - lasso\n",
    "    - ridge\n",
    "    - elasticnet\n",
    "    '''\n",
    "    if reg_type == \"lasso\":\n",
    "        best_alpha  = gsCV.best_params_[\"alpha\"]    \n",
    "        best_lambda = best_alpha * 2 * factors.shape[0]\n",
    "        print(\"best lambda: {}\".format(best_lambda))\n",
    "        return best_lambda\n",
    "    elif reg_type == \"ridge\":\n",
    "        best_lambda = gsCV.best_params_[\"alpha\"]    \n",
    "        print(\"best lambda: {}\".format(best_lambda))\n",
    "        return best_lambda\n",
    "    elif reg_type == \"elasticnet\":\n",
    "        best_alpha   = gsCV.best_params_[\"alpha\"]\n",
    "        best_l1ratio = gsCV.best_params_[\"l1_ratio\"]\n",
    "        best_lambda_1 = best_alpha * 2 * data.shape[0] * best_l1ratio\n",
    "        best_lambda_2 = best_alpha * data.shape[0] * (1-best_l1ratio)\n",
    "        print(\"best lambda1: {}\".format( best_lambda_1 ))\n",
    "        print(\"best lambda2: {}\".format( best_lambda_2 ))\n",
    "        return best_lambda_1, best_lambda_2\n",
    "\n",
    "\n",
    "def best_subset_regression(dep_var, exp_vars, max_vars=3):\n",
    "    '''\n",
    "    Best Subset Regression \n",
    "    '''\n",
    "    def best_subset(x, y, l_0):\n",
    "        # Mixed Integer Programming in feature selection\n",
    "        M = 1000\n",
    "        n_factor = x.shape[1]\n",
    "        z = cp.Variable(n_factor, boolean=True)\n",
    "        beta = cp.Variable(n_factor)\n",
    "        alpha = cp.Variable(1)\n",
    "\n",
    "        def MIP_obj(x,y,b,a):\n",
    "            return cp.norm(y-cp.matmul(x,b)-a,2)\n",
    "\n",
    "        best_subset_prob = cp.Problem(\n",
    "            objective   = cp.Minimize( MIP_obj(x, y, beta, alpha) ), \n",
    "            constraints = [cp.sum(z)<=l_0, beta+M*z>=0, M*z>=beta]\n",
    "        )\n",
    "        best_subset_prob.solve()\n",
    "        return beta.value, alpha.value\n",
    "    \n",
    "    # perform best subset regression\n",
    "    betas, alpha = best_subset(exp_vars, dep_var, max_vars)\n",
    "    betas[np.abs(betas) <= 1e-7] = 0.0\n",
    "    \n",
    "    return betas, alpha\n",
    "\n",
    "\n",
    "def display_betas(betas, names):\n",
    "    '''\n",
    "    Simply returns the betas coefficients (from a linear regression model) in a pd.DataFrame.\n",
    "    The input betas vector has to be a list or a np.array\n",
    "    '''\n",
    "    return pd.DataFrame(betas, columns=[\"beta\"], index=names+[\"alpha\"]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $y_t$ represent an asset return at time t, the linear factor model can help us interpret the source of the \n",
    "asset return and attribute it to the factor returns. \n",
    "\n",
    "In the following example, we are interested in explaining the asset returns with a **five-factor model**:\n",
    "- **World Equity**: this factor represents worldwide equity returns.\n",
    "- **US Treasury**: this factor contains returns from treasury bonds in United States, the bonds with the least risk.\n",
    "- **Bond Risk Premia**: this is a credit factor that captures extra yield from risky bonds. It is defined as the spread between high risk bonds and US Treasury bonds.\n",
    "- **Inflation Protection**: this is a *style* factor that considers the difference between real and nominal returns, thus balances the need for both.\n",
    "- **Currency Protection**: this is also a *style* factor that includes risk premia for US domestic assets.\n",
    "\n",
    "We have the data for the above factors and for the following set of assets:\n",
    "- **US Equities**:\n",
    "- **Real Estate**:\n",
    "- **Commodities**:\n",
    "- **Corp Bonds**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Regime-5</th>\n",
       "      <th>Regime-7</th>\n",
       "      <th>US Equities</th>\n",
       "      <th>Real Estate</th>\n",
       "      <th>Commodities</th>\n",
       "      <th>Corp Bonds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1985-01</th>\n",
       "      <td>0.028511</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.006408</td>\n",
       "      <td>-0.016265</td>\n",
       "      <td>0.030292</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.056605</td>\n",
       "      <td>0.021351</td>\n",
       "      <td>0.048963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-02</th>\n",
       "      <td>-0.009204</td>\n",
       "      <td>-0.044692</td>\n",
       "      <td>0.057381</td>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.010258</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.030075</td>\n",
       "      <td>0.016448</td>\n",
       "      <td>-0.015217</td>\n",
       "      <td>-0.042029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-03</th>\n",
       "      <td>0.075134</td>\n",
       "      <td>0.028719</td>\n",
       "      <td>-0.024396</td>\n",
       "      <td>-0.002848</td>\n",
       "      <td>-0.020739</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.007299</td>\n",
       "      <td>-0.006716</td>\n",
       "      <td>0.037171</td>\n",
       "      <td>0.032666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-04</th>\n",
       "      <td>-0.002459</td>\n",
       "      <td>0.023084</td>\n",
       "      <td>-0.004869</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.008187</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.012255</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>-0.035116</td>\n",
       "      <td>0.037125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985-05</th>\n",
       "      <td>0.040245</td>\n",
       "      <td>0.086780</td>\n",
       "      <td>-0.044417</td>\n",
       "      <td>0.004077</td>\n",
       "      <td>-0.002219</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.027241</td>\n",
       "      <td>0.004351</td>\n",
       "      <td>0.104199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         World Equities  US Treasuries  Bond Risk Premium  \\\n",
       "Date                                                        \n",
       "1985-01        0.028511       0.031500           0.006408   \n",
       "1985-02       -0.009204      -0.044692           0.057381   \n",
       "1985-03        0.075134       0.028719          -0.024396   \n",
       "1985-04       -0.002459       0.023084          -0.004869   \n",
       "1985-05        0.040245       0.086780          -0.044417   \n",
       "\n",
       "         Inflation Protection  Currency Protection  Regime-5  Regime-7  \\\n",
       "Date                                                                     \n",
       "1985-01             -0.016265             0.030292         1         1   \n",
       "1985-02              0.006362             0.010258         1         1   \n",
       "1985-03             -0.002848            -0.020739         1         1   \n",
       "1985-04              0.003089             0.008187         1         1   \n",
       "1985-05              0.004077            -0.002219         1         1   \n",
       "\n",
       "         US Equities  Real Estate  Commodities  Corp Bonds  \n",
       "Date                                                        \n",
       "1985-01     0.081301     0.056605     0.021351    0.048963  \n",
       "1985-02     0.030075     0.016448    -0.015217   -0.042029  \n",
       "1985-03    -0.007299    -0.006716     0.037171    0.032666  \n",
       "1985-04    -0.012255     0.000906    -0.035116    0.037125  \n",
       "1985-05     0.064516     0.027241     0.004351    0.104199  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factors_assets = get_factors_and_assets()\n",
    "factor_names   = list( factors_assets.columns[:5] )\n",
    "asset_names    = list( factors_assets.columns[7:] )\n",
    "factors_assets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAFFCAYAAADbx1X2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3WdgVFX+8PHvvXOnZtJ7QiD03kFEUVHEirL+QbEsLu5ad11de0Fs67q2R11711XZVSwrKlYUQRAF6SX0hPSeTMr0ued5ccNADAlJCCTA+bwxc8u5Zy7IL6f9jiKEEEiSJEmSdNipnV0BSZIkSTpWySAsSZIkSZ1EBmFJkiRJ6iQyCEuSJElSJ5FBWJIkSZI6iQzCkiRJktRJZBCWjlkPPfQQU6dOZerUqQwZMoQzzzwz/Nnr9TZ7n8vlYtasWQcs/4MPPuDPf/7zQdVx7dq13H///QdVRkdbvHgxEydO5MILL8Tv9x/253/33Xc899xzh/25knQoaJ1dAUnqLPfcc0/459NOO40nnniCoUOHHvC+6upqNm7ceCirFrZ9+3ZKS0sPy7Naa8GCBVx66aVcffXVnfL89evX43a7O+XZktTRZBCWpGasWLGCxx9/HJ/Ph9ls5qabbmLChAncdddd1NfXM3XqVObPn8+8efP44IMPCAQCuFwurr32WmbMmNFsuR988AGffPIJ9fX1xMTE8NZbb/H+++/z/vvvo+s6cXFxzJkzB7PZzPPPP09tbS2zZ8/m3HPP5dFHH2X+/PkA/PTTT+HPTz31FBs3bqS0tJRBgwaRkpJCaWkpJSUlFBQUkJaWxuOPP05CQgLvvvsu8+bNw2w2Y7PZePDBB+ndu3ejOvr9fv75z3+yYsUKVFVlxIgR3HnnncydO5cffviB5cuXU1NTw6233trovueff55Fixbh8/nweDzcddddTJo0ie3btzNnzhz8fj9CCGbMmMHFF1/c7HEhBC+88AILFy5E13UyMjK47777yMvL48MPPyQUCuF0Orn44ou54447cLlcgPHL1F//+tcO/psgSYeQkCRJnHrqqWL9+vXhzxUVFWL8+PHhY1u2bBHHHXecKCgoEDk5OWL06NFCCCFqa2vFRRddJKqqqoQQQqxcuVKMGTNGCCHEvHnzxHXXXdfkWfPmzRPjxo0TtbW1QgghfvrpJ/H73/9eeDweIYQQP/zwg5gyZUqTMpYtWybOP//8cDn7fn7yySfFOeecI4LBYPjz5MmTw8+48sorxXPPPSf8fr8YPHiwqKioEEII8dFHH4l58+Y1qeOTTz4pbrzxRhEIBEQwGBS33367eOCBB4QQQtxyyy3izTffbHJPbm6u+MMf/iC8Xq8QQohPPvlETJ06VQghxO233y5ee+01IYQQxcXF4qabbhKhUKjZ4x988IG4+eabRSAQEEII8e6774prrrkmXLeHHnpICCHEv/71r3C96urqxA033BD+zpJ0JJAtYUnajzVr1tCrV69w93T//v0ZPnw4K1asYOTIkeHrnE4nL774IosWLSInJ4esrKxWdZUOGDAAp9MJwA8//EB2dnaj1nNVVRW1tbVtqvOIESMwmUzhz8cff3z4GYMGDcLlcmE2m5k8eTIXXnghEydOZMKECZxyyilNylqyZAl33HEHmmb8E3HZZZdx8803t/j8jIwMHn74YT799FN2797NmjVrwu9i8uTJ3H333axdu5bx48dzzz33oKpqs8d/+OEHNm/ezLRp0wDQdX2/488nn3wy11xzDfn5+Zxwwgncfvvt4e8sSUcCOTFLkvZD13UURWlyLBgMNjpWUFDABRdcQHFxMWPGjOHGG29EtCIdu8PhCP8cCoWYNm0a8+fPZ/78+Xz88cd8+OGHREZGNrpHUZRGZQcCgWbLBLBarY0+77n3qaee4oUXXiAjI4OXXnqJ2267rUn9QqFQo+8vhGjy3X9rw4YNXHLJJdTX1zNhwgSuvPLK8DNPP/10vvrqK84880w2btzIlClTKC0tbfZ4KBTi2muvDb+TDz/8kHfffbfJM0eMGMF3333HhRdeSF5eHtOnTycrK6vFekpSVyKDsCTtx8iRI9m2bRsbNmwAYOvWraxevZpx48ZhMpkIhUIIIdiwYQOJiYlce+21TJgwgUWLFqHrepueddJJJ/HZZ59RXl4OwNy5c/njH/8IgMlkCge/2NhYCgoKqKysRAjBggUL2vy9ysvLmThxIvHx8cyaNYsbbrgh/B1/W6f//ve/BINBdF1n7ty5nHDCCS2WvWLFCoYPH86sWbMYM2YMCxcuJBQKAXDjjTfy7bffMmXKFO6//37sdjt5eXnNHp8wYQLz5s2jrq4OMH5xuOuuuwDQNC38Th599FFeffVVJk+ezD333EPPnj3Zvn17m9+LJHUW2R0tSfuRkJDA008/zf3334/f70dVVR577DEyMjIIBAIMHDiQKVOm8N577/Hxxx9z1llnoSgK48aNIzo6mtzc3FY/65RTTmHWrFnMmjULRVGIiori2WefBYxfBl588UVuuOEGnnnmGaZNm8a0adNISEjglFNOYevWrW3+XldddRUzZ87EbrejaRoPPPBAk+uuv/56HnnkEaZOnUowGGTEiBHhINic8847j4ULF3LOOeeg6zoTJ06kqqoKt9vN9ddfz5w5c5g7dy4mk4mzzz6b0aNHExUVtd/jI0eOpLS0NNxFn5aWxsMPPwzA+PHjue2229A0jSuvvJI777yTKVOmYDabGTRoEGeddVab3okkdSZFtKbvTJIkSZKkDie7oyVJkiSpk8ggLEmSJEmdRAZhSZIkSeokMghLkiRJUieRQViSJEmSOslhX6JUVta2LEBHAqfTSl2dr7Or0enkezDI92CQ72Ev+S4Mx+p7SEyMbPacbAl3AE0zHfiiY4B8Dwb5HgzyPewl34VBvoemZBCWJEmSpE4ig7AkSZIkdRIZhCVJkiSpk8ggLEmSJEmdRAZhSZIkSeokMghLkiRJUieRQViSJEmSOoncTxhYvfpX7r33LjIze6IoCvX19aSlpXPffQ9hNptbXU5RUSH33Xc3r7zyVqPjEycez5Ahwxodu+++h0hMTGpShs/n45tvvuS8837X7HPWrl2N0xlJnz59W103SZIkqeuRQbjB6NFjeOCBf4Y/33//bJYuXcypp55+0GVHRUXz3HOvtOraysoKPvvskxaD8IIFnzJp0hkyCEuSJB3hulwQXrCphE83FndomecPSeHcwcmtvj4QCFBRUU5kZBQAL730HOvWrUbXBTNmXMZpp53OmjWrePPNVwEIBv3ceed9bWo1A6xfv5bnnnsaTdOIjIzkvvse4u233yAnJ5s333yVc889nyeeeAS/30dNjYtZs64iKSmZX35ZzrZtW8jM7MXmzRt5//25qKrKsGEjuO66v7apDpIkSVLH8wRC3P15FmcOSGJmC2kru1wQ7iyrVv3K9ddfTXV1FYqicP75/8eYMcexfPkyiooKePHFN/D5fFxzzRWMHTuO7Oxd3Hvv30lISGTevHdYtGghZ5xx9n7Lrqlxcf31V4c/JyYmcd99D/Hjj4s55ZRTueSSmSxduoSamlouv/yP7Ny5gyuuuIqVK3/h4osvY9SoMWzYsI7XX3+Zp59+gXHjxjNp0hk4HHbeeONlXnvtHWw2G3//+xxWrvyZsWOPP1yvTZIkSfoNIQT//HY7S3dVsrO8npkn92722i4XhM8dnNymVmtH2dMd7XJVc9NNfyE1NQ2AXbt2sHXrlnAQDQaDFBcXkZiYyNNPP47d7qCqqoKBA4c0W3Zz3dEzZ17B22+/wY03XkdiYhKDBg0hEPCHz8fHJ/Dvf7/OggXzAYVgMNjo/vz8PKqrq7j11hsAcLvdFBQUMHbswb4NSZIkqb0+WlfEl1mljOoWzep8V4vXytnRvxEdHcOcOX/n0Ucfory8nB49Mhk5cgzPPfcKzzzzEqeddjrp6ek8+uhD3H33fcyefT9JSU0nWLXGt99+yTnnTOHZZ1+mZ89efPrpxyiKihA6AK+99hJnnXUuc+b8nVGjxoTvUxQFIXRSU9NJSkrm6adf4LnnXmH69BkMHtz8LwOSJEnSwXvlpxz+8c02NhTWNDmXX+3hyR92ckLPWJ6dNpQkp6XFsrpcS7gr6NmzF9Onz+Dppx/n739/hDVrVvHnP1+Jx+Pm5JNPxeGI4Mwzz+Hqq2cRGRlJUlISQpQ1W95vu6MBrr32egYMGMxDD92Pw+FA0zRuv302sbGxBAJBXnjhGU49dRL/+tcTvPPOmyQlJVNdXQ3AoEFDeOml53jggX8yY8ZlXH/91YRCIVJT0zjttMmH8M1IkiQdub7ZUsrSXZU8cHZ/FEVp0711viBOq8b6whpeXZ6LqkBWSR3vzhzV6LoP1haiC5g9uR8WTeXNS0e2WK4ihBBt/iYH4WjcTzgmxkF1tbuzq9Hp5HswyPdgkO9hL/kuDJ39Hi57exXbyuqZO3MU/ZKcB7y+2hPg9Z9zWbargrxqLxP7xFNU46O01sfUoSm8tSKPb647nliH0dr1BEKc+/IvHJ8Zy8NTBobLkfsJS5IkSce0vCoP28rqAfh6S/M9l/t6ctFOPlhbSPdYBxePSufnnCpyKt38bWIvJvaJB2BlbnX4+i+zSqn1BbloRFqr6yW7oyVJkqSj3sJtRuDtlxjBt1tL+ctJmai/6ZL+OacSVVFQFYXlOZV8lVXK5cdlcP1JPQG48eSemFQFRVEI6YJIq8aK3dWcMSAJIQTz1hTQLzGC4elRra6XDMKSJEnSUe+X3VUMSHIyc2w3Zi/Ywo87KzmloTULENIFsxdsoca7dxVKnMPM5WO7hT9rpr2dxyZVYXRGNCvzjJbwqjwXO8vdzDmjX5vGm2UQliRJko5qIV2QVVzHuYOTOa1fImk/ZvPvFbmc3DsuHDCzSmqp8QYZ1yOG3gkRXDW+B2aTilVrftR2ZLdofthRQVmdj5eW5ZAQYeGMAYltqpscE5YkSZKOarur3LgDIQanRKKpCpeO7saGolp2VhiTxEprffy4swIFeOicgdw0sTdOq9ZiAAYYnh4NwPNLc1hXWMOV47tjM5vaVDcZhCVJkqSj2qYiY1XOoBRjlvKE3nEArMl3UeMNMO2NlbzxSx4Dkp3EOFqffrh/YgQ2TWXBphK6xdiYOiSlzXWTQbjBrl07ue22G/nrX6/hyisv5/XXX+Ywr95q4vzzzwTgnXfeYvPmjfh8Pj777BMAvvjiM5YuXdyZ1ZMkSToibC6uJcJiokecHYC0KBtJTgur81ysLajBG9RJclqYMrhtQVQzqQxJMyZhXXNCZqMx41aX0eY7jkK1tbXcf//d/OMfj5OR0Z1QKMScOXcyf/5H/O530zu7esycOQswtkrcs8PSOeec17mVkiRJ6uLeWZlHSa2PLzaXMjw9KjwbWlEURmXEsDK3mpQoK2aTwsd/Ou6A3c/7M3VICjE2rc1jwXt0uSBs3fIhtqz3OrRM78CL8Q1oPpguXbqYUaPGkpHRHQCTycQ99zyA2Wzm2WefYv36tQBMnnwWF110Cf/4x/1omkZxcRGBQIApU6awcOFCSkqKeeSRJykpKebdd9/CbDZTWlrC1KnTWL36V3bs2MaFF17CBRdMZ+XKn3nllRexWq1ERUVz11334nA4eOyxf5CdvYv09G74/UYe6X/8434mTTqDxYu/D++wpOs68fHx/O530/e7y9PHH3/Al19+Ht5d6S9/ubFD36kkSVJXVu0O8MySbABGdYvm7smNt34d2S2ar7JK+SqrlEHJke0KwABnDUzirIHtS10MsjsagPLyMtLS0hsdczgcrFjxM0VFhbzyylu8+OLrfPvtV+zcuQOAlJRUnnrqeXr0yKSgIJ8nnniGiRMnsWzZEgBKS0v5xz8e55Zb7uLtt99gzpwHeeKJZ5g//2OEEDz22MM8/PDjPPfcK4wYMYp///t1fv75J/x+P6+88hbXXHM9Pp+3UZ0uv/yPZGb25Iorrgof23eXp2eeeYm3336D2tpavvjiM2688VZefvlN0tLSm2z+IEmS1NVVewIs2VnRrnu3ltYB8Oy0Ibw8YzgpUbZG50/uFUes3Ux5vZ+R3aIPuq7t1eVawr4B01tstR4KycmpbNu2pdGxwsICtm7NYvjwESiKgqZpDB48lJycXQD06zcAAKczkt69jW2qIiMj8fmM1muvXr3D+wSnpaVjNpuJjIzC7/dRXV2NwxFBYqLx29OIESN5+eUXiImJYeDAwQCkpKSQlHTg3aSa2+Xp7rvv5b//fZeXXnqWwYOHdsBbkiRJOrzm/prPWyvymHNmP1IirYztHtPqNbh7gvDA5P2njExwWnnhomE8/t0OzjyIluzBki1h4MQTJ/DLLz9RUJAPGIHs2WefIjIyKtwVHQwG2bhxPd26GV3WB/qL0NLpmJgY3O56ysvLAVi7djUZGd3p0SOTTZvWA0brvKyscWq1fXdY2qO5XZ4+/fQTbr31Lp577hW2b9/Khg3rWv9CJEmSuoA9KSH//vU2/vLhBhbt2H+r+Pvt5fxh7hq2ltSFJ9RuKa0jNcpKtL352c59EiJ4ecZw+iREdHzlW6nLtYQ7Q0SEk9mzH+DRRx9C13XcbjcnnngS06fPoKSkmGuuuYJAIMBpp51O//4DDvp5iqJw++2zmT37NlRVITIyirvvvp+YmBjWr1/HVVf9gZSUVGJiYhrdt+8OS1arFYATTzx5v7s89e7dh6uuupyYmFgSExMZNEhucShJ0pGjzhckq6SWcwYlEWnV+HpLGd9tLeO0vglNrv1ycwmbi2v5/buribRq/PuykWwtraN/KzZp6GxyF6UO0Nk7g3QV8j0Y5HswyPewl3wXhra8hx93VnDzJ5t46aJhjM6I4eFvt/F1Vhlv/34k3WLsmNS93Y0X//tXrJqJSX0TeGFpNmcNTOKLzaVcdUIPrhrf41B9nVaTuyhJkiRJRwxvIMR/VuVj1VSGpBrrcCf1TcQdCDH9zV/5z6p8bvx4A88s3kUgpJNT6eG47jFcflwGJ/WOZ8HmUkyqwuR+7Vs2dDjJICxJkiR1Gd5AiJs/2cSqPBd3TOoTXjo0tkcMN5/am17xDv6zqoCfsqv4ZbextWBIF+Fx3d8NSwVg1nEZZMY7Ou17tJYcE5YkSZK6jEcWbufX3GruO6s/5w7eu0JEVRQuGWUsJX1y0U4Adld52FZq7BHcO9EIwidkxvLSRcPCeZ27OtkSliRJkrqMlbnVnDEgsVEA3tekholZJgV8QZ0lOyvQVIXMWCMlpaIojM6IQVNbv51gZ5JBWJIkSep0eVUeqtx+Suv89IpvfslQUqSVOyb14W8TjfwMi3eUMzA5sl15m7sC2R0tSZIkdapqd4BL3l7FqIbMVd0bWrXNmT4ijTpfkP+3aCchAaf1a7ps6UhxZP7qIEmSJB01vsgqwRfUWZ5TBRDe7aglTqtGktMCwKl94w9p/Q4l2RKWJEmSOsXynEoe+nobvmDjTIAZMQcOwgCDU6NIqfeTHt2667siGYQlSZIOguPXf4EQuMf+rbOrckTZVFzLLZ9sIt5hod4f4qyBSXyVVUpKpBWb2dSqMh44uz96J+/7frBkEJYkSToI1i0fgGaTQbgNhBD8v+93EGUz8+7MUTitGp5AiK+zSlvVFb2HvZXBuiuTQViSJKm9Qn5MNXkI65GxJrWr+H57ORuKaplzRr/wBgtOq8b/DU9lUDO7Hh2tZBCWJElqJ5NrN4oIoXgrIeQDk7Wzq3TYvf7zbnZXenjwnNZtbiOE4M1f8ugea2+yFvjO0/seiip2aXJ2tCRJUjuZqneEf1bry1q48ugkhODDtUV8s6WUen+wVfd8taWUraV1XD62W6NNGI5VMghLkiS1k6lqZ/hn1V3SiTXpHFtL6yiv9xMSsL6w5oDXv74sm3u/2ErvBAdnD9x/RqxjjQzCkiRJ7aRV7wr/rNYfe0F46a5KFIwUkmvyXQe8/suNxQxMdvL2ZaOwaDL8gAzCkiRJ7Waq3kkwth9w7AVhIQTfbStncGokA1MiDxiEAyGdzUU1jM6IkQF4H/JNSJIktZPJtZtAyiiEqmE6xoLwitxqdpTXc8HQVMZkxLChsIaSWl/4vC+oc928dSzbVQnAtrJ6AiHB4JRja/bzgcggLEmS1B4BD6qnnFB0JrojEdVd2tk1Omy8gRCvLd9NnMPMmQOT+N2wFATwzso8tpbUAfB1Vim/5rn4Msv45WRTUS0AQ1JlEN6XDMKSJEntYKrNB0CP7IbuSD5muqOFEPzlww2sK6jhLxN6YtVU0qPtnNw7nvfXFPL7d1ezs7ye/64uAIyxYiEEv+ZVk+C0kBx57C3jaokMwpIkSe1gqskFIBSVgR6RjFpf3Mk1Ojx2VrhZX1jD3yb24vyhKeHjN5zcixkj0wB4b3UBO8rrGZDkpLTOz78WZ7NoezkXjEhHUeSypH3JICxJktQO6j4t4VB0JiZXDuitWyt7JFuebYzxTuqX2Oh4RqydW07tTZzDzGebjF6B60/qCcDcVflM7BPPLZP7Hd7KHgFkEJYk6ZgTDOm4PIGDKsNUm4cwWdEdiQTjB6CEfEYgPsotz6mid4Jjv93KiqIwLC2KkC7olxjB2B4xxDnMDEuL4u/nDJDJOfZDBmFJko45b6/MZ/qbv+INhNpdhlqTTygyHRSVULyRstFUsaWjqtgl1XqDrC1wcXyPuGavGZYWBcD4nnGoisK7M0fxwoXDWr0z0rFGBmFJko45G4pqqPYE+GV3dbvLMNXmoUdmABCM7YNQVLSKrI6qYqfzBEI8uySb6z9cT7Xb6DX4YG0hgZDg7EFJzd43rkcsmqpwat8EABKdVqxyXXCz5AYOkiQdc3aW1wOwaEc5p/SJb1cZppo8fL2GGB80O6HonmhHSUt4fWENcxZkUVjjw6QqXPz2KnzBEIGQ4MSecfRPcjZ7b78kJ4v/eqJMyNFKMghLknRMqfcHKarxYVJgyY4KcircZMY72lSG4i5H9VYSiukVPhaKH4BWtrGjq9spXliajT8keHnGMGq9QV7/OZee8Q62ldZz7Yk9Dni/DMCtJ4OwJEnHlOwKNwB/GNedj9YWctk7q7jvrP4U1fiYOiSFGIf5gGVoFZsBCCYOCR8LxvTGsutL0EOgHnnjn7oQzP48i5N6x7O70sP4zFhGdYsB4JQ+CZ1cu6OXDMKSJB0zNhXX8l5DEokpg5K5aEQaf/1oA7MXGN3IQghmjeveYhlayZpwizeYMCh8XI9IQhE6ircS4Uhs7vYu68edlSzcVk55vZ/yej8ZsfbOrtIxQQZhSZKOGQ98tTXcEk6LtmFSFZ6dNpS3VuTx3uoCtpbWt3i/qXIbsR+eB0DImYqwxYbP6Xajtai6ywgdYUFYCMGbvxjJR9YVGFsS9pBB+LCQQViSpGNCeZ2P7Ao3Q1IjOa5HbHjNanyEhVtO7U1xjZdtZXUtlqHWFoR/DiYMbnROdxgzhlV3Ge1f+NQ5cio9bCqupXusndwqD4BsCR8mh2T0fPny5cyePftQFC1JktQuv+YZW+3dPqkP152Y2eT8gGQnuVUe6nzNZ73ad5OGYPygRueEo6El7CnrgNoeXj/urADginEZ4WMZMTIIHw4dHoR3797N5s2b8fl8B75YkiTpMFmZW0WUTaNf4v6X1+xZdrO9rPku6T3bFdaPuw3voEsbndMbuqDV+iMnCNf5gvzz2+18vqmEfokRTOhlLNdKclpkco3DpMODcI8ePfjTn/7U0cVKkiS1mxCClbnVjOoW3WzqxAENQXhrqdElvTK3iu+3NQ6oqrsE3RqNe8yN6FHdGj/D7ERoNlRP+SH4BofG8pwqPl5fRHalm5N6xxNjN5McaaV7XNuWbEntJ8eEJUk66hW4vBTV+Pj9mIxmr0lwWomwmMivNsZEn12STaHLyyl9EsKBW60vDY/9NqEo6PZEVHfnt4SFECzZWcG4HrHkV3tJi7bhsDRt2e75heOq8d25aEQ6ALPP6EukVYaGw6VNLeF169Yxc+ZMAHRd595772XGjBnMnDmT3bt3H5IKSpIkHayVuUZ6yrHdY1q8LjXKRqHLizcQYltZPS5vsNFkLbW+BD0iudn7dUfXCMK/5lVz6/zN3PzJJi57ZxX3frH/TF5bS+vomxjB1SdkhtdHj8+MY0hq1OGs7jGt1b/uvPrqq3z66afY7cZg/cKFC/H7/bz//vusXbuWRx55hBdffDF8/RNPPLHfcpxOK5p2dI01mEwqMTGy+0a+B4N8D4YOfw81+Zi+u5/QmY+Bo/kNBPZnXXEtSZFWRvSKb3E/2+7xDgqrveTVBwjpAoD1JfWM728EXs1bhkgc3+z3MkWnoFTnNDl/uP9OrFxuNIpW5lZjNiks3lnBDpePMT1iG123o7yek/smHra6yf83mmp1EO7evTvPPvsst99+OwCrVq3ipJNOAmDEiBFs3Ni6dG11dUffhK2YGAfV1e7Orkank+/BIN+DoaPfg33d/3Bu/piAz0fNWS+3+j5vIMSyHRUcnxmLy+Vp8doEu5kVOZUsbxgLTom08sPWUmYMSwEhSKgtwWuOp76Z7+U0x2Gt/aXJ9z7cfye+yyplTPcYhqVFcUrveG7630ZeX7KTPuftndFdXuejvM5PzxjbYavbsfr/RmJiZLPnWt0dfeaZZ6Jpe2N2XV0dTufeWYYmk4lg8Ojf0FqSpE4SMn6Bt+5cgNKGLt93fs2n2hPggmEpB7w2JcpKnS/E8pxKusXYOK1fAusLXCh5y4l/cxSK7g93R1d7AgRDeqP7dXsCiqcS9M77t3BHWT25VR5O7RPPdSdmMijFWBe9rrAGIUT4uj2JSVrajEE69No9O9rpdFJfv3cqv67rjYK0JElSR9p3rNVSsLxV91R7Ary9Io9J/RLCeZBbkhplA2BVnovh6dEMT4/GHxJ4N/4vvP5XdyRR5wsy/Y2VPPtjdqP7dXscCgLF52rt1+pQ5fV+bv90E5FWLbyVIMDQ1CjK6vwU1+7tiVxX6MKkKjIId7J2B+FRo0axZMkSANauXUu/fv06rFKSJEm/pbpL0W3GWLBam9+qez7dUIw3qHPl+APv/AOQGmWRTmphAAAgAElEQVQFQAAn9ozjxOAv3Kf9G1vRL+FrQpHpzN9QjMsb5LONJXgD++TH0ozxTiXobdXzOlJ2hZtZc9dQVufnqQsGk+i0hs8NTzMmWq1vSEkJsCbfxcBk535nTUuHT7ubrpMnT2bZsmVcfPHFCCF4+OGHO7JekiRJjajucmPrwCodUyuCcFAXfLQ2n9EZ0fRJiGjVM1KjjZawSYFxPWJIe+dWrtBqwQP14+7A3/1kfPFDee/TlSREWCiv9/P99nLOGWR0UQuzMXFVCbY89tzRQrrgvi+34A/qvHrxcAYkNx6D7J0Ygd2ssqGohpP7xFPg8rKpuJZLRqUf1npKTbUpCHfr1o158+YBoKoqDz744CGplCRJ0m+p7jJCsb0h5EetydvvNabyzdi2z8c19jZe+9+nfOW/gzU9n2/1M2LtZqyaysBkJ1E2M8IWB/5aANyp4/i2Ko1+mpfiWh+zJ/fl9Z9zWbKzYm8Q1jonCH++qZiskjoePKd/kwAMoDV0O28treONn3N5a4Xx/kZ2iz6s9ZSakoO4kiQdEVR3KYH040FRMFVu2+81tqz3cKx/gxWhvlxW/AhRqofR6jY8nNGqZyiKwjUn9DBSW+oh1PpivFo0uX4nz66z81lWFjNGpgHQKyGC3gkR5FXtDbhCM1rSHObu6K+3lNEz3sFZA5pJJAIkOa1kldSys9yYyxNp1RieJoNwZ5NBWJKkri/kR/VVozsSEZodS853IATss+Z3VV41g3atoTswfv0dmFU/wmTFVJ3dfLn7MXOskVVLrclDCfmoO+kBzluUiS+rCoCF24y0lD1i7XSLsbG2wIUQAkVROqUlHAjprC+s4XdDU1pcA53gtFC+y0+i08rI9CiemTZU5ofuAg7JLkqSJEkdaU8+Zt2RSCiyG0rIh7InR3PQS73Xy+zPs4iq3YZAxSp8LI69iEDyCDTXrnY901Rt3Kcl9GFin/jw8Yp6PzF2M9F2M2nRNur9IVyehiVJe4Jw4PAE4ZxKN99tK8cX1Bl1gK7leIcFT0Ant8pDfIRVBuAuQraEJUnq8vYsT9IdSaAYbQdTTR5BWyzxb4yg1D4Ss/siYmz1PK9PxxUyM+L4Wwnt/n9Ys79u1zNN1TsBCEb34pJRNsrq/AghWFNQE97wvlvDdn/5Lg8/7qpg+9YC/snhaQkLIbjxow0U1hjLjg40vpvgtADGMqb4CPMhr5/UOjIIS5LU5YWDsD0BYTaWAWnlG9HK1qMG6hgc+JE/9jobCmGncwzx/ScwKjOJkKsXqqcCxVuNsB14nfC+tOpd6GYnwpHI4AiFl2cM56VlOUYQjtsThI0x4IVby3l/TQGJuhtshycI76xwU1jjw6RAn0QnsQ5Li9fHR+w9nxDR8rXS4SODsCRJXY45dzHCHk8wcQgAan0xYHRH6xEpBBKG4FwyB0UYa3R1FGYkF0Eh3H3p+QirsS42FNMLAJMrm6BtZJvqYKrONu7fZ5y1X6Kx1CmzYau/tIbkHnNX5ZPktNDdEQc1oPs7LjVjRb2f5TmVTBncOOPXsl2VxrMvH02M/cAt20ZB2CmDcFchx4QlSepyIhfdiuOXx8OfzQU/o9vi0J1pYDLj+t08fP2n4Rr1N+4OXImKwLn9I4LRmeEADBCK6Q3s7VpuC1P1rnAQ32NYejSJTkt4/HXfcdXrJmRy6kBjj2Gft56O8r/1RTzw1TZKG7Jd5VV5COmCpbsq6JtozNCOb0XLNkG2hLsk2RKWJKlrCXgw1RUhzA3rXUMBLLmL8PQ4A1Qj6AlrFLWTnmRTcS2/LP8cAFNdIZ7BMxsVFYrKQKBgcuW2rQ5BL2ptPqEBFzY6nBBh4Ytrjm90rHusndwqD2cPTGbBxoYWu99NR017yqk0WtWFLi+KAv/3xkriHGYq3QH+MiGz1eVE2zQ0VSGoCxIirAe+QTosZBCWJKlLMdUY2/CZavNACMxFK1B9Lu7c0oM/n+Bv1IrbWlrHbpGMrppR9QD+jJN+U5gF3ZGEWlfYtjq4clAQTVrC+/P6JSOMe1QFq9mEW1gRHTg7OrdhHXJhjRcdYwOGSneAoamR/H5Mt1aXoygK8REWSmp9siXchcggLElSl2Jy5QDG5CbFU44l+2v8ioWF/kH02VLKpaO7IYTguR+z+WFHBVaLFT2mJ0rVDgLdTmxSnh6ZhqkNQVgr24BWvAqgVUF43/FYq6bixdxhQVgIwe7KhiDs2psA5KaJvThnYDKaqW0jigkRFirq/UTb5T/9XYX8k5AkqUvZE4QBTDW5WLO/YakYigcbCzaVcOnoblTU+3l7pZE/uluMDX/3UzFF90RYmy7T0Z1pmCq2tOrZir+WmI+nQcPs5tYE4X1ZzSoerB22Tri83o+7YYOIQpcXk2pMErtgWCr2dqzzTYiwUBFhaTGph3R4ySAsSVKXsm+GK2v2N5hq81kQODuc+/gPc9cwbXhq+JoLR6RRP3pOs+WFnOlYdn/fJMPW/li3fYISNMZgQ45khKVt2/xZTCpeYcHeQUuU9rSCTQoU1XixaCpRNq1dARjgiuO7U1nv75C6SR1DBmFJkjpP0ItWtSO8FAmMlnAwrj9a5Vbsa19FoPB9aBQvnDOApbsqeGZJNuV1xkzhhX8eT/QBlufokWlG17avGnP+MhQh8PU9r+mFQmDb/B+CsX1Q60sIxfRs89exaUZL2NFBLeHdVcYvBMPSoih0ebGZTSRHtn9S1eCUpps7SJ1LBmFJkjqF4qsh9r1JmOqKqLxsyT5renMIpI1Dq9yKovtZZxuLqiWSGWenZ3wGn20sIbvSTZLTcsAADBByGhsumGrzcS57EGGy7jcIm/OXYS7bQO0p/yQU06vNrWAAq2bCgwUl1HEtYZumMjw9mndW5mEzm0hr2G5ROjrIICxJUqewbXwbU10RYEyGCsX0QvHXYqorwBvbJ3zdHfWXctKg+PA45nE9YsiudNM3sXVBUo809sw15y3FVFeIQEHx1yEsTkwVW3AumY130CXYN7xNKCIF78CLwNS+1qZVU6kTVtQO2kVpd5Wb7rF20qNthATsqnDL7QePMjJZhyRJnUKr2oFuj0eoWnjilKk8C4BgwmCqz/8PK0f/iy2BZE7sGRe+b2z3WAD6NmSvOpA9LWHblvcBUBCYKoznRKx8CkvhL0Qt/BvmktW4j7ul3QEY9syOtqB2YEu4R5yDMd33ptw8mO5oqeuRLWFJkjqFMfbbD9VTidYQFLXyTQAEEwejR6Tw4fYdWLVixu4ThMZ0j2Z4WhQn9Y7fb7m/Jezx6OYII+hbo1F9LrSyjegRyVh2fYl7xDX4u5+C7kwjtE8LvD0sDWPCppCX4EGVBP6gTlGNl7MGJtEtxh6emBZpbd0/22pNHnpktwNORpM6l2wJS5LUKUyuHELRmQTjB6BVbEEIgVa+Ed0ej+5IRgjB0l2VjO0e0yg9ZIRF47VLRjAsLaqF0vehqNSc9QqBpOF4RlyLbotFK9+EbevHIASe4VcSyDj5oAMwNEzMEha00MF3R+dVe9AF4c0i7jmjL3EOc6NWcXPMhT8T/854Y1a41KXJlrAkSYed4q9F9ZQTis40ZiVvn8/U57/jq5gNmBIGg6Kwu8JNgcvLzLGtzwrVnED3U6jufgoA5oKf0Mo2IGp2E0wYjO5MPcDdrRduCeu+gy5rd0OmrB6xxmYRA5Ij+fq68a26177qeQC00nX4MycddF2kQ0e2hCVJOixiPjw/vCmDyWWkpgxFZ1LuMFqgmYHtRNRsJ5gwCIAfd1UANBoP7gj+jJMwl2/CXLSSQPoJHVq2qigEFAtm/eBbwrkNOaO7N+xd3Fqmii1YcxcZP1duO+h6SIeWDMKSJB1yis+FuWQ1ltwfQIhwQo5QdE8WVScBMM36K5oIEEwYDMCy7Er6JkaQEtWxS3K8Ay5EqBqKHiTQrWODMEBAtWEWfhB6u+4vr/dT7w+yq8JNQoQFZyvHgPewb3oXoVoIpI5Fk0G4y5Pd0ZIkHXJ7J15lEfn9Ldi2zAMgFNWDxSXZTCOCc5SfQMCtPylklOWwNt/F5cdldHhdhCMRf88zsez6ikDqcR1efkC1gQCCXjA72lY3IbjqvbV0j7WzqaiW8W3tBQh4sG77H77eZ6NHZmBf+xKE/GCSGzZ0VbIlLEnSIaeVGbOeFd2Pbcs8hMlKIGUMutnB6oIaSm29cei1eIWZ7yqief3nXEKi47ui96g76QFc573TaO/hjhI0GS13pR2pK3OrPORXe/kpuwqXN8jp/RLadL815xtUnwvvoEsJxvVF0YON0oDuj+KtIu7fY7Hs+LzN9ZUOngzCkiQdcqaKzQh1b3Yr19mvUT3tE7aX1lPjDRKMHwDAFpFBQqTReoy2aQxJ7fggCaBHpBDIOPmQlB1SG4JwO1JXrsitBoxc0REWE8dntu2XEHPuEnRrNIH08YTi+gMcsEvaXLIGU10RkT/cieIua3OdpYMjg7AkSYecVr6ZQNrx6NZodEtkeMvBZdmVAER1HwaAkjSE56YPZWhqJGcNTArvGnQk0cMtYXeb712xu4q0KCvXnJjJH8d1x6q17Z9oS8FPBNLHg6ISjO2D0GxoRSuMXaGaGaM2lW826htwE/ndze0ey5baR44JS5J0aIUCaBVb8Qy7gmD8AITZER6j/GZrKcPTorCnDQWg16BxeOMcvH7JiCN2uz2/ZqTTVPy1bbpPCMGqPBen9U3ginHd2/xctSYPU20e7hFXGQc0G/70E7HmLMSS/yOh2L7UnPVKk+QdWvkmQlHdcY+8lsjFd2PbNBfvkJnGST2I4q1COBJ/86x8dEc8aG2buS01JVvCkiQdUlrlFhTdTzBpOPUT7sM97jYAdpbXs7PczRkDEgkmj6T2pAfx9f8/gCM2AAN4NaMLXfVWt+m+whovtb4gg1Lbt9ORJX8pQKNlV/7MSZhq89CqdmDd9SWW7K+b3KeVbyYYPxDv4JmEnKmYi1eFz9nXvET8v8di3frx3hsCHmLfOx3Hr8+0q577UtxlRH59HWptwUGXdaSSQViSpENKK1kHQCBpeKPj760uwKTAaf0SQVHxDvsjwnLkb7XnNxsbLCi+tgXh7aX1APRrZU7sRoSOff2bBKMzw2PBAP4eRqKOQMIQgjG9sK9/o/F9ATem6l3GsjBFQbcnongqwqcteYtR9CCR3/0NtWFtt6XgJ9RAHZb8ZfuvSyiAZecXoDdN3KmuepOor6429nYGnEvvx7bjM6w7F7T9Ox8lZBCWJOmQCQZDbFn3I0FrLHrU3i7WdQUuPtlQzIxR6SREHF3LZ4INQbitLeHt5fUoQO+Etgdhy64v0So24x57U6PuZj0ynboT5lB36mMEE4ag1hUadavJw7b+DSz5S1EQ4bXZwh6H6jXG6QkFMJeswZc5GUXoWHd+AYA59wfA2PmK/cwAd6x6huivrsa6fX6Tc8rGeVh3fkHEsgeInXsKtoZr9m19H2vkmLAkSYdG9W7i3jiN1EAVG21jSN4nOHywtpAYu5lrTsjsvPodIiFrJDpK21vCZfVkxNqx75Mnu7Vs2z4h5EzD1/d3Tc55Rl4DGDPCTTnfQsBD9IJZaJVbEaqFYHQm/oaUnrotDnPVTgC0is0oQS++fheg1pdg3/g29k3voHir0C2RqP5aHGtfxd9tAsGUUQCYKrfjWPUsANbt8/H1n7a3InoQpXg9AI51rxGM60/dCfdgLlmDVvyr0To+goch2ku2hCVJOiSU7MVYA1UAlNl7Nzq3tqCGMRkxOCxtDzhdndVspg4HShtawjmVbraW1rV6e8bf0krXEkgdC2rz71OPSEYJeohY+SRa5Vb83SeCHqDu5IdAM2Z06/Z4lIaWsLloJQCB1DH4ep+DqTYPJVCP4q/DPfqvAET88hjRn14afoZ1x2egh/AOuAhL3hIUr/Hnr7pyMBcsRwl68Pafjrf3FKov+AjPyGvxp4/HVF9yzI4Ly5awJEmHhFq4ilrFyUeBE8iPPIchDceLa7yU1PqYOebQrAHubBaTSrVwktTKlnB2hZuL3voVgPOHJLf5eWp9Maa6IjzJI1u8To8wyrbkfEswtg+uKe+g1hc32sBC2OJQA/UQ9KKVrCHkTEN3puEddCmqpxzPiGsQmg1hjcGSuxhLwTLUQJ2RHUyzYS74iWDiENzD/oRtyzxsWfMIJo8g+rPLIBQAwD3mBkIxvcLPDKaMAcC+6R3qj78DlGOrbXhsfVtJkg4bPW8lq0K9uT84i63BvcFlbUENACPSozuraoeUVVOpFhGtbglvKDTex3UnZjJtWFqbn7d34tuIFq/bE4S1qh2EonsaE7F+s4OUbjeSg6jeSrTS9QSTjPXbwh5H/YT70Z2pCFssKAquqe/hOutlo8yKLAh6MBevJpB+AqHEwfi7TcCx+jmiPr8c3RqNIkIIa5Sxc9Y+ggmD8PU+F8fq55tOHDsGyCAsSVKHU/x1mCq2slbvTbRNo8oTCJ/7eXcVERYTvdvZ9drVtTUIbymtI8JiYta4DGIc5qYXCAH++mbv10rXIlSNYOLgFp+zJwgDjVqija5pCMIm1240VzbBxGHNF6goBBONGe/W7fNxLn0QRfeHl0jVH3cLqrcKYU+gevrneIb+AX3IRU1buopKzZkvEYztiznvxxa/w9FIdkdLktThSrcuIwGBo8dxHG+OZUORkbjii80lLNhUwvThqWhHYDas1rBqKtU4UbzFrbp+S0kd/ZKcqM1MSor8/mZsWz6g7OrtYP5NcgwhsOxeZMxuPkDijFBEyt6fo3vu9xphM4KwOW8JAIHEoS2WqUemo9vicKx7zfhsjSaQNg6AYOpYXFPeNvZsjkim7uR/EBPjgOr9ZBJTFILJI7DsXnTMTdCSLWFJkjqcZd3rVAonp546hTiHhWp3AF0Invsxm2FpUdx8au8DF3KEsmomqoWzVbOjg7pgW1kdA5KMLFumiq1oRb9CyAeAuWA5ti0fAKC6S5rcby74CXP5RryDLm1yrunFDnSLMQ4fitl/ENbt8QBYchcb9UtqoSUMoCgEkoYjVDNV0+ZTMWsVwuIMn/b3OK1RC7wlgaThqJ7y8DKqY4UMwpIkdShT+Wb6uH7iU9tUYqJjiHWYcQdC/JpbTVmdnwtHpGE2Hb3/9Fg1hWoiMPldB8zDvLvSjS+oMyDZiW39G8S+dzqxH/8O5+LZANjXvhq+Vt0nicYejjUvotsT8e67FKgFewJis0F4T0u4bD0hZxqiISi3pH7Cfbim/pdgyujwLOv2CDYkc9FK17a7jCPR0ft/giRJHSfgRitd36pLzds/IyhUCvpcBkBcwzjnR+uKMJsUJvQ6NNsTdhVWzYRLOFGEjuKva/HatQUuAIZH+3D+eB/+HqfhTzveWB7kr8eSt9hYekTTIGyqyMKS+wOeYVe0OvjpEckIzYa+T9f0voR172Q5fyt3mQrF9iGQdnyrrm1JMGEQQjVjLl130GUdSWQQliTpgOwb3iTmo6ktThDaI7T7JzaKngzp3QOAGLuREWvxjnLG9YjFaT26p6IYE7MaNnHYT5e04qnEVLkNc+5ipi0/j36RQTKDu1AQeEZeQ6DbiZiqd2Hd+TlKyIdnsPHLzG+DsGPNywjNgWfPZgutEEg/AV/m5OaXAe2zzrhVXdwdyWQlGD8wPNv7WCGDsCRJB6RVbkPRA6ju0pYvDHpxVqxnpT6A43oaLd49LeGQgFP7tm2T+iORMTHLmPm9v9SVUV9fR9x/T8O+6nkSQyVckFyGVmXs+RuMG0AwcRgKgoiVT6Pb4vD1PBvAyOkc9BL59XWYKrZg3bkAb78LjCVDreQecwO1Z77YqmuDB1h3fCgEk4ajla0/prZTlEFYkqQDMrlyAFA95S1el71xKRoB7L0mkOC0AhDbEIRNCpzc+8BjjEc6q6ZSJYyNKLblZOMLNg4opppc47rCnwA43lmKVrGFkCMJYY8Lz0g21ebhHTgDLBHo5ghUTwVaxRZsOz4j4pfHUYIeAmnHdXj9q6Z/RuUl33fKDOVg0nBUfy2m6uzD/uzOIoOwJEkHFA7C7rIm59T6EggYifwLN34PwKkTzwmf3xOER2fEEGPfzzrYo4xNU8kRxpjrNz/9xNdZjXsPQs69CTlCQqGXyMNUsYVQ/AAAREQSoYhkhGLCM/QK45g9HtVTjqmmYSejnG8BWl7H207B5JGE4vp1eLmtEWiYja0dQ+PCMghLktQixVcTHo9s1BIWgqjPLyf+rdFEffc3fEGdftVLyLYNwhK5t8XrMJs4d1ASM8d2O9xV7xQWTaWSKOq0OAYoeZTV+xqdV71VhJypLI69iLX0x1G9Fa1qG8F9tiD0Dv497tHXo0caAVu3x6N6KjG5jFa0InSE5mg26caRKhTXD6HZZBCWJKmLCnqJ+PFeYt87Ha0hwf6htqcVDPu0hIVAK9+Idff3hJxpWLK/YfuG5QxScqjPPKvR/YqicP/ZAzg+8+ieFb2HVTMmNxVZe9JPzafKHWh0XvVW4e9+Gi/brqDIkom5ZBVK0EuwoSUM4B57E+5xt4U/6/Z4FE8Fak1O+FgwcXCLGzYckVSNYMIQtLKNnV2Tw0YGYUk6gti2fohj/RuodUVEffOX8C41h9Jvg7DiqSD+9aFEfnsDQjFRe+pjKHqAvr/eBUDCyAsOeZ26Mqtm/LO625RJPyWf6nrv3pNCoHirKA9FUFDtpSbCWK8rFBP+XmftrzhgT0u4HFNNLiFnOnDgbFZHqmBcX7TqHZ1djcNGBmFJOoKY85cRikjBdf5/MNUVYt/47iF/psllTJIJRXVHdZehVW5F9VWjVW0n0O1EAhmn4HX2oJt/F1uc4zHF7T8RxLFiTxDeqfTArvgx1+WFzyn+WhQR5L9ZbgprvFQkjEO3xeE6/z+N1uj+lgh3R+8mkDaO2pP+Hh4vPtqEYvqgeioOyy+YXYEMwpJ0BFB8Lkzlm7HkLyPQbQLBpOEEkoZj2b3wkD/bVLWTkDONUGSGkVaw1kgrKDS7sUZVUXgy6nb+HLoVZfo7h7w+XZ2tIQhv0Y0Wa7x7b6tuT2ApCToJhATmlEFU/Gk9gW4ntlimbotH0f2Y6goJRffAO+wK9GayXh3pQrF9AOPv3bHg6F41L0lHAXPBcqK+uga1YbN1f7cJxn97nIZj5dMonkocq58HVaN+/F0d/nytYgvBuP4IaxTmkrWYavMBKP/TBtBsuP0h/p0bz5TBg4iLaH/awqOFpSEIZ/mTAIjx7c2FvOfPsAojmUd6dCszXTn2TnQLRffokHp2VcFYI6+4VrWDYOqYTq7NoSdbwpLUxdk2vg2Ar+eZCM1OIGNPEJ6EgsCSuwjblg+MvVgblgp1GD2IqWoHofj+6I5EVHcZal0Buj0xnCpx6a4KfEGdMwYkduyzj1CqomA2KRT5LNQJGzGBMnRdAOCvM2aZ71lHnB7d8s5He/i7n4Z3wIUEEocSSD34FJFdmR6ZgVAtmI6RcWHZEpakLk6tLyUY15eas19D8dcirMZOOMGkYej2eGxZ74VbWJbd3+HvM6XDnm1y5aDofoJxA1Dri1GCbrTK7YQija7WkC6Yv6GYRKeFEenNj2kea6yaSo03RJElnhSlApc3gAK4KktIBhITU4iu0UiJsraqPGGPo3bSU4e0zl2GaiIU0/OY6Y6WLWFJ6uJUdwm6IxkUJRyAAVBU/OknYClYDhgzbG07Pu3QZ5sqtgAYLeGGHXi0sg3oDUH4ngVZrMit5pJR6c3uh3sssmomBFAk4khVKqio8wNQX20s8Zo1cRifXHncUb2b1MEIxfQKTwg82sm/AZLUxZnqS9EjkvZ7LpBuTOgRiglfnymYC1d06LO1yq0IFIKxfQikjQdACfkIRXZje1kdC7eV88fjuzNzbEaHPvdIt2eGdJGIJ1WppNJtBGFvbTkhoZCamHzUb2RxMHRH4n63bjwaySAsSV2VECj+OpSgG93RTBDudgJgzCgNJo1A9ZSjuFvO79wWWkUWoehM0OzoUd0IJI0wnheZzuebStBUhUtGpnfY844W1oYWbhFxJOKissbY0jDkrqBGceK0WTqzel2ebotD8VaDHursqhxyMghLUhcV/eklRH11NUCzLeFQdE+C0T0JpB1PMN5Ie6hVbj2o5yreKtCDRlllmwgmDgmf8zWMN/sdaXy5uZSTescT4zj680G31Z6WcLGIR1UEvsoCADRvFbWqHDs/EN0eh4LY71aQRxsZhCVpH2p1dpfYRk3xVmPOX4YlbwmAMSa83wsVqqd/Rt2Jcwg15B42HUwQDnqIe3cCjtUvonirMdXmEUwYHD7tHXARnkGX8EVtb6o8Af5v2P43hz/W7QnCdVbjzy3kygch6OPPotjcvTOrdkQQdmNJ1rHQJS2DsHR0C3qxZH8LocABL7WvfZX4uSdhyfnuMFSsZeailSiI8OfmuqMBhC0GNBu6IwndGoNWsRVz7mKc398KQW+z9+3/uatQfS7MuT+glW8CILhPekRhj6Nm4mO8tqaafokRjOvR+r1sjyV7gnCtxfhzs9QXo5WtJ0FUsDGi5cQcktEdDXvXVR/NZBCWjlqKp5LYD88n+osriFjxeIvXmso24Vz2AABaeecnjzcX/tzoc3Pd0Y0oCqGYntg3zyXms8uwZ72H1jC7ubUs+UuN55euxVy8GqBRdzRAVnEtu6s8XDq6G4qcEb1f4SBsNv7cHN4iLNnfEEJlV+wJnVm1I4Le0BJWZEtYko5c1p1foFVsxp82DvvqF9FK1+//QiFw/ngvuj0eodm7xIbi5sKfCcYYmYOEyYqwxrTqvkDKWOO/ySMBUOsKW7q86XPzlyJUC0rIhy3rv4ScqeGuwT3WFtQAMK5H6+p0LNoThHWLExdOnJ5CLLk/sEb0RXXEH+BuSdiMHhbVc/Tnj5ZBWDpqmap3IDQ7NWe/DooS3gj9t2wb3sRS9Av1424jkDIGU3UnJ40AwEIAACAASURBVAkQOlr5Zvw9JxNyJBld0a1scbqPu5mKy37Ede5b/P/27jMwjupq+Ph/ZrZJu+qy1SxbknvDBfdKNxAMsWM6hicQSvKEBAgJCTyUEEKSNwmQBAghQAqEDjYQOphmjHHvVZZt9V53tXVm3g9ryxaWbVlaaSX5/L4Yr2bv3h1WPnvbOQCau6zdL6sEmrBUbcI36vLwcxsLCR5IkXm4DSUNZCU4SHW1L9HEyehgEHZYNMqUNJL8pWh1+WzWc+RoUjsYMQeno/v+SFg+DaLPstTtJpQ0BNORiJ40tGUkbN+1BEvNdvy581A9FcR9cQ/+nLPxjbwcS8127DtfB9Nsd+CLNNVTgWIE0eMHERwwCyXoafdzTZsL0+YC08RUbaie4wfhuuYASzeXc21WCYppEBh0BoqvFtPqxD3nV63bN002ljQyI1fWgo/lYE1hu0WlUkvnVN9GVNPDPjOddAnCx6fZMawuFG/fXxOWT4Pos7S6PQTTwwngQ/3HYdu/DMVTSdyy21F0P/ZdSwmljkaPG0DjuX8DVSOUOISYQBNKcxVme9Zhu4B6oECCHjfgwKi0A18GFAXDlYF6nJFwUDe4481trC9p5JwJm0gFQqmjCOT8tc3rC+u81HmDjJMUlcfUMhK2qlRbM3CGvgRgn5nOEAnC7RIu39j3R8IyHS36pmAzWlMxevLQ8F/7n4LqrQ5vvjKCNE/8IZq7FNv+ZQQGngZaOHmCfrCCSxSTx2uN4fqzRnw2qBZQtQ61o7syjjkdvaKgmm8/tYr1JY0oQKh8K4YjCcN59GNH7++oBGCKrAcf0+HT0bW2jJbHC8x04iQIt4vhSEI9CWoKSxAWfZKlvgCgZXNTqN8pADh2v4F/yHyax30PEwXF1Alkz2l5np4Y/VqmWstIuHOZqI41Eg589htOe2cmqbYgjywcw/j0GOIad+JJGM7RTkmHdIOlm8uZlpPU7uo/JyvbYSPhenv4/6OhWCg1U3HZO/al6mRjxCSjHH5EKeQl7sOb0aq2Rq9TXUCCsOgTlOZqCITXTh1bnyPhrSsB0JPCI+FQ6ij02P4EMqfhnvsgZmwqofRTMRW1VUF1w5WBYYs74aM9naU27Cf539PR6vJRm4oOlArsXKAzXBmonvI2k4/Eb3uOBMXDs1lvcpp1O680XMxwfRcvlyTx4rqSNttbXlBLlTvAonEZbf5cHOI4EITtFo1GRzgIN8UMQEcjziEj4fb45nS0tWIDjl1LSHj3e+GUln2EBGHR+5kmSa9dRPzHPwY9QOyqhzEVC4EBs9AT88LXWBzUXrOKhgWvYtrD65meKbfjmfF/LX8HwmdtU0ZiqdnWrW/BVrICrakI+5530RqLOz0KBtCdGShG8IizloZpUm6EqzGl7H4B56o/YDHDaSp3mNl8uLOqzfbe3V5JcqyVmXlyxOZ4Dl8T9jnSCaFS5wgXuZDp6PbRnRmonoqWGtkHK3qp7lLilv0kvHmyD5AgLHo9S/UWtMb92PZ+QOy6x9GaK2g64w80XPQiaIflNVZb/+MXzJ6Fd/wNR7QXSh2JVr29W9NXajXbgfA5XbWpCD2+81WJDFdmuO1vnBXeVemmv1nDvn5nYqpWrGWr8eZ9ixWZ3yNu7IVsKWuiosnPlwW13PPODp5bU4zbH2J5QQ1nD++HRZUEHcdzaE1YxW6z819jJjsS5gIShNsrlDYexdSxVoVPNVhqtmPYE/HM+D/se9/Hsf2FKPcwMiQIi97LNIjZ+BQxG57EPLCD2LnqD4RSRhEceFqHmw2ljEINult2KXeHg9Pf1vI1aE0lGHEDOt3mwVkArXZXq8fXF5SSoDQTm30q/sHnA+AffQVDF9zHeROGAfDxrioe+GAX7++o5NEv9vL82mICusm8EdHZMd7bHDqipBFj1bgl8H1WuM7BoiotAVocWzBtIgD2/LdwLr8Pa8UGQqkj8Y77HnpsGtayNdHtYITIVzLRa1kqN+Fafh8AwfRJhPqNRm0qo+mM33fqjG8oZWS4/eptBOK7Idm+aYZLBh7YzWxqdvx553W6WT1pMIbVhbViA/4RFx94KZPt+eGg7EgeQPPICzCc6S3r4jnJsQzt5+Rfq4qobQ5y3bSBPL2ykL9/VciYjDjGZMR1ul8ng8M3ZvlD4f+ucgeIs1sk1Wc7mbGp6PGDiNn8z5bHmk+5Nnz8ztm/z6S0lK9kotey7V+GiUIgcyreU67FPefXNH7rmSPSLJ6oUMoITEXFtv+TCPX02NTmSlRfHd6x38U7+irqL3yBUPrEzjesqIT6n4KlckPLQ2uK6mmsLgTAiMtET8zDM/PuVlP13xqVRm1zEAW4dEIm03KSUBW448whEkDa6fDp6BhreFRc5fbLpqwTFEw/FQDT4gBATxkR/ntMMqo3cnWzo0mCsOi1bPuXEUqbQMOC1/APvTByDVtj8Y1ZTMy2/2Db807k2j2Kg+vBobTxuE/7LaHMKRFrO5Q2Hkv1NtD9LN1Uxv3v7WK4owEIb3xpy7wR/VAVGJsZT1KsjV+cNZRHFo5hRJqMgtvL0TIS1lqCcKU7ICkrT5B/8HmEkofTMP85Qol5BLLCxS+MmNQ+k8hDgrDolRRvDZbKjQRyzuyS9t0z7yWUkEPMtv90SfuHs9TuBiB0oB5wJOyrbebed3fgSTkFxQhSU7CeBz/cTUKMlcuGhkezhqvtpBypLjs/OX0IN80cBEBmgoPpOckR69vJIDcllpFpLob1cxJjPTgd7SdOzgifkEDeedRd/jHBzGnUXfk5RkIOcDAIy0hYiKixVG9FwSSYMblrXkCzEcyciqVyc5cfhdDq8jEcSZ2eRgdo9AXZUdHEY1/s5Z1tlXzWnIepaNSseQFNVXhkwWiytXqMmFTQjl6A4ZIJmUweKPmhOyo51sa/r5pIerwDx4GRsDdokBRri3LP+gYjJhkl5INgc7S7cnzHqWUuQVj0SlpdOK1k6EAyjq4Q6ncKqq/2hMsBniitLh89aUhE2vrz53tZ/Nx6Ps0PT9W9UwjuYYuYXPMG38kzSXXZ0Rr2obsk4UZ3OTgdDZARL5WnIsGISQXoFaPhhDcvP+bPJQiLXslStwfDFo954JexK4T6jQ2/VtVR6hBHiKU+n1AEgrBpmny9r47EGCsDk2I4Z3g/Vuyt5UXHpYDJLerLKN5arGVft1miUHSNg9PRABnxjij2pO84+HuvNvfsIKz46rGVrjzmNbJLQPRKWv2ecLGFLtytG0odialoWCo3E4jAkaG2KL46VG9NS87qzihp8FHe5OdnZw7h4vGZrC9u4IOdVfxmlY+E+G9zSeFr+L60oBghfEO/HYHei/ZwyEg44g7VG+7ZpQ6t5WuPe42MhEWvFMkp3KOyxKAnD8e+5+1wbuoucHBaPRLvZXVhOJ/u5IHhCkcTBiTw87OGoKkK6oxb0eOycex8lVDSEPTUUZ1+PdE+h09Hp8tIOCKMnj4SPpBtz1K+BlM99lhXRsKi11ECbjRPOd4DFZK6knvGXSS8ex3J/5mDb+SleGbdG9H2LbU7AQgld35t+/M9NfRz2RiUdKjww3fGZXLhmHSsmkrd4PdxbH+JUL/RXTqDIFo7fDo6PU5GwpFgHNjEqPSwNWHFV4/ri3uw579J43lPYy1bRSh1NNZjPEdGwj2R7ifhrauwHmct4WQVydHj0SzbXc3KfbX4BsyhfuFSQv3GErvx7yj+xoi+jn3PO+iuzE6nqdxe0cTygloWnpJxREINqxb+NTft8XjHX0/wwFlL0T0OjoSTY62tpqZFJ1hjMS0xPeussB4g/r3rsee/hWmJJXb1Q1jL1xPMnHbMp8lIuAfSGouxFX6KrfBTqm4qaCk4L8JshZ8CEOp/SsTadPtDPLummGsmZ7O2qJ473gxXUZqVl4zTppHjPodf8CWWmm3H/aU6Htu+jzAVDT0xF1vR53im/ASUzn0ffuLLfSQ4LFw2sfPVl0RkWTUVq6bIVHSEGTGpaI2F0e5GC8fO17GVfEXjWY+g1RXgXPtnTNWKd+z/EHuM50kQ7oEOL2Tt2P4ivjFXR7E3PYfiqcRW9Dn2XUsIZE1vqRIUCZ/vqeGZlYXUNwf5NL+aIalOzhnRj8eX7wOgP6n8wgGWqq2dC8KmieuzOwET/9BvYyoavpGXdarvm0obWbG3jh/OzpWMTD1UjFWTTVkR5s+bR+zGp7DveBX/iEVR6YN91xLU5iq842/AWvoVRkwq/mHfQW3YR+zav+AbeRnGcSqiyW9sD9S6kPV6CcIHxK57lNhNzwDQNOHGiLadX+UB4PVNZTgsKo9dPILBKbH4Qwa6YfLKBpVGNRFb9dZOvY7auL+ltGDMpmcI5JyF0YEzuwU1Hn7+5nYGp8aSX+0hOdbKJRMi96VERNaVUwYy+LC1etF5nul3YanajGv5vQTy5mHaujmtqmniXPk7VG813jFXYy39mmDm1HCBicRc6he9SSh5xHGbkSDcAx3cdh9KyEGr23NCz9WqtqJgtJxx7Uu0xiIAAlkz8Q++IKJt51d7SHXaiLVp/O/sXIakOgG4aWYOAEHdZMOmbAbtWUvRWDfD+7s69Dq2khUAmCgouh/f6CtPuI1GX5D/fWUzIcNkdWE9CTFW7jx7aKtduKJnue3sYdTX94LsTr2JZsUz426SXr0A58rf4ht+MaG08d328paqTWgHyp06dr6G1lSMd9z1LT8PpU1oXztd0jvRKYr3QBDOmIxt7wfhtInt2c1qmiS8dwOmxUHd5R93cS+7n1aXj3/w+TSe+2TE295T7WHKoER+eV7b31x/ODuHwprxZJY9z/znv+LZ784mM+HE1/isxSswYvoRzJyMpWorgey5x7z+T58V0OQP8X/nDGt5bE1hPdWeAI9fPFZSS4qTWihtPIGBpxGz+V84tr5A9fXbwNI9a+/2Pe9gKhqoFmJXPwxAoANLVbI7ugdSvbWYlhhCqaNR/Q3t3oZvKVuN1rgfrXZXxHfxRp0eQGssJBSBpBbf1OgLUukOtIx+22LRVIZP/zZWRWc+X7CptAP31zSxlnxFYMAMGs94mLqL/wvqsUevy3ZX8972SoK60fLY1vImLKrCuMyEE++DEH1M49l/wTP5NhQjgFZf0D0vaoSw736D4ICZBLOmo3nKCfYf31Jq8URIEO6BVF8thiO5JZWhpb4dU9Km2VLxR8HEUrmx7babSo4M0KZx5IWmSezXf8C++60T6ntX0RoLUUwdPSkvou2WNfp4csV+AAYfIwgDBDOmEOg3luss77GjvOGEX0urL0BrriCYNR1sTkzHsUexbn+I0gYf/pDBjgp3y+Nby5sY1t/VUjheiJOZ6UjCPzic0c5Su6tbXtO29/3w9POYq/FM/Rnu6XdSv+DV436pbov8FvdAircGIyYF/UAyioPnYo/KCBH/9jU4dr6Gb9gCTBSsFeuOuExt2Efyf+aQ8sw4Ytb/DUI+4t+7kaTnT0fx1be61rbnbZxrHiH+g+8Ts+6vEXtvHXVwbVyPcIKOPy7bw0vrS7FqyvHXeRUF/5hryFNK8ZZuOeHXsh5YD27vOd2Dm8UAPs2vYWeFG90w2V7uZnS61PYV4iA9MVwtTOuOIGyaxG58Cj1+IIGcswn1PwXvxB90eBpcgnAPpPpqMWOSMOKyMDU7MZv/ibXoi6NeH7PxKez7l+GefhdNZz6CnjQUS/mRQdj15a9A0QhmzcC58jckvr4A25530Br24frsF4dev34vri/vJ5QyEv+gM4ld86eoT29r9QcSdEQwCO+raebzPTVcPXkA/71hKinO45/HDvUbA4BRuxfjBEscWou/RHemoyfktuv6XQeCcILDwr9XF3HNf9bx5d5amoO6BGEhDqfZ0RNysNR1fRC2Fn2OtWw1zeNv6NDI95skCPdAqq8Ow5ECiopn8q2o7jKcBxb+Dzo4clV8dThX/QF/7jy8E24CVSOYPiE8Ej4sSFiLlmPf+z6eST+i8ZxHMe1JaPV7aTz3CZon34Ij/y0slZuwlqwg6ZXzUYIemk7/fzRPvR016Max9bkOvx8lAlltrGVr0V2ZmPb4Trd10CsbwiPgKycNILmddV71hHCh+3S9lKI6b/tfzDSxlX4VHgW3M2Xk7io38Q4LF43NIDnWiqIo/N/b27GoCqdmy3qwEIfTk4cdeyQc9EKojd9ZPYjrk5+R+Nq3iVn/RNvLc4dxfv3/0OMG4Bt1RSd7HCZBuAcKT0eHq4R4T/0hgZyzUQ/LDGPftYTUp8cQ/94NOHa+hhLy0Tzpxy3/uIfST0X11aE17A0/wQjhWn4vevxAvOO+h+lIou7i/1J35acEBn8L7ynXYVpicX32CxLeWozhzKDukvcJpU0g1G8sgayZxGz+13E/nG1xbP4Xqc+MQ6vq+Pla1V2Gbf/H+Ict6HAb32SaJl8U1DA9J7ndARjAtMURsCczSKmgoKb9R0602p2o3hoCA2a2+zm7qjwM7efkB7NyeOfGacwb0Q9v0OCGGYMk+5IQ3xBKHobWsA9CviN+5tj0DP2eHErCW1cd+bOdrxCz7XmUoBvXigdwrvj1UV9DbdiPtXIj3nHfi1gmQwnCPU3Ihxr0YDqSWx7S47NRPRWg+wFwbHkOw5GMreA9nF/+Cj1+UKtzwcG0iQDErvkTia99G8fW57DU7sQ9466WdQsjLgvDmQ6Ecwr7RizCWrmRUOoo6he+hhF/KJexb9TlaO4SrCVfndBbUQJNxH1+F0Cba9TtYSlbg2v5fSimjjdC3zwB9tY2U9boZ0Ze8vEv/gY9IYdBSgVljb5wdaVjfDkJGSbLdlejFC4H2r8e3OQLsbOiiXGZ8WiqgqYq/HBOHredPpjFk4+dgUeIk5GeOBjFNI5MZRn04vrqtwBYS1d940kBYlc/QjBtAnWXfog/dx723UtbzSIezlYcXhYMDDw9Yv2Wc8I9zMFEHQdHwgB6/EAUTLSmEkxFw1b2NZ6pd6B4q4jd9Az+Id9qNcWpJw3FsLpw7HwNAEvFOkJJQ45ZE9cz+VZ0Vybesd8FW+tdwv68eRi2eJyr/ojXU4YS9OLY/iKN5z6JERfOVawE3KC3/jg5Nv+r5b8PVgs6Ea5P7iBm238wUfCOuhLjwFRwR+yscFPp9jM+K4E4h4UvC8L3eUZOB87ZJuaSU/Ep79XXkfzcIrzjrqd56u1tXvqnzwp4cV0Jw5I/JD4u+7gp7A5aXVSPbsK0nEOfg1SnjcslN7QQbdITw3sttPq96MmHztXb932IEmomkD0HW9Hn4SlpSzh7mbVkBZq7FPecB0BRCOSchX3v+2i1u9BThh/xGtai5eiuDPTEyJ3SkCDcwyjeOgCMw46vHPyHW20sxFa8HBMF3/DvYNrjUQwd75hrWjeiaoTSxmMrXo7uTA+X/Rt3/TGLBJix/fCe+sO2f2iJwTv2Gpxr/4K17NA3ydg1j+A+/fcAJL7yLZQhZ8DUA6X+TIOYbS8QyJqOEvKj1ew49hs3TdSm4pb3qtUXELPtP3hHXYFn5j2Yto5lqDJNk0c+K+D5tSUA9HfZ+O38USzbHc4P3ZFpXSMxh0ylhsSq1ahBD7aN/6B5wveP+PKyI38XszbfyY6U/yXHvZF9mWfSnhXtNYX1vLutAqdNY2yGbMASoj30hByA8JT0Yey7lqI70/ENvQhb0eeo7nLQbMSu/yvoAUzNTiB7NkBL8hxb0Wd4vxmEDR1b8XICuedEtBSoTEf3MGpzJQBGbP+Wx/S4gQBYy9YQs/mf+IcvxIjLxLS5cM/9dcto9HCB7LnosWnUf+cN3NPvxNfJBOfN0+6g6qa91H3nDRrPeRzvmGtwbH8ZtbEIJdCEpX4P6tbXwAgBB87RNe7HN+pKQikjwiPhY+wmtu9+g5RnpxP3wQ8h5MW+awkmCs2Tb+1wAAbYUNLI82tLWHhKBn/+zhgsqsJtS7eypayJi8amd6jNg7/sI6rfB8AabOCjV//M37/a3+o6bedSLtBW8sTQDSQpbt5zH39XdIM3yPdf2cSn+TVMHpiIRZNfUSHaw3QkYdgTD+2FOcBa9jWBQWe2FHzRPOXYdy8lZvM/idn2fPjc/oGRsRGXSShpKPbdb4Kht2ondt1jqP56/LnzItpv+Q3vYdTmKqB1EDacaZiqNfzNzQjhmXzbcdvxTriJ2qtXYMRlhc+waRGo4KJZCaWfin/ohTSPvx7F1LHtX9byzVPx1mIt/RrHtheJf+9GQgm5+PPORU8ejuqrC3/BMM02g7Fj+4sYtngcu5cSu+6vOHa+TnDAzA4VNzjc3trw5qn/mZrN9Jxk7jx7GPXeILFWjQtGp3WozVDKKADOYiW7jSyKzVRs1Rv559eF1DYHWq5Lrf46/Of+NwF4uzqNiib/Mds+uNlrWk4SNx7IWy2EaB89IafVSFjxN6D6G9ATc1v2wKiecqyHJTMKDDytVRvNE3+AtXIDzq//34E2GnF98lNiV/0B39CLwiPhCJLp6B6mrZEwqoYel4WlYR/eMde0b21UUSITeI/CiB+E7kzHWrYK05HY8njMpmewlq4kmDGFxvOfAYuD0IFUbjGbnsG+awne8Tcc2NhgoicNQXWXYi3+kubJt2Cp2oxz9UMAuGfe0+l+Ftd5sWoK/V3hezE1J4mrJg2gf5y9w2X/9JTh7E2YRm7DSjYyjJFaGaMcbgINJq9tKOOnmYmgBxjk2QCApW43hmplt5nFG5vLuGFGzlHbLqgJnw2+6+yhsgNaiBOkJ+a22nx1sOiLHj8Qw3UgCLvLsVRsJJgxGcOeiH/I/FZt+EdcjLdsDbHrHsPUbFgqN2Er+gzfmKtxT/tFRKeiQUbCPY7qqcCwxYG1ddkzI34QpsVB86QfRaln36AoBDOmYC1b3ZKvVZ9yE/a976MEmnDPeaDlTG8wYxLBtInErnsMzV2KfcerxL97HQlLL4VgMzEbnkTBxD9sAZ4pP8VUrTRPuIlAXuenfYrqvQxIiEFTD/3i/HhuXqc3OO0e9gMMU6E0YRKDcwczNNbNnMEpPLemmKK6ZqwV67GbfjxKeJ1YTx7GnGHp/GtVEftrj360qaC6GadNIy1Oas8KcaL0hBxUd2nLMSW1MbxEZMQPxLTFYVidWKq3oLlL8OeeS+O3/oHhPHJGzD331/iGXIhz9cPY93+Me9Z94c1btmOntu0IGQn3MGpzVetR8AGe6T9H8dW1+YGJlmDGZBz5bx7YMZiFcdavaXZkg6m3TmSu2alf8AoxW55Dq93VkuMaIOHd67EWfY539OKWHYc131133LzK7VVU72VAYuRHlLbsScxZ/jDn5E7EMGtRCz/j9gsGc/m/1vLz1zfz9JDwuegNCWczs34peupobp86mJX76vjbiv08eMHINtstqPGQmxKLEuFv20KcDPSE3PBJkob96CnDDxsJhzd8Gs507HvDezlCaeOO3pBqoemcx/COvx7VU0EgwuvArV6qy1oWHaI1V2LE9jvi8VC/sQSz50ShR0cXzJgCgK3s63AAVRR8Y6/Bd8q1R16s2fGOuw7v2PBOblO14M85C1vRZwQzpuCeeXfLpZEKwIZpUlzvI7sLiqkPTnWSlzeSeSPTMJxpqEE3mY4QP5qbx6p9dezZv5eQqVLdL1zaLJQ6ilSXnXkj+rO8oAZfUG+z3YKaZvJSYiPeXyFOBnryUAC0ut3hPxsLMewJmPZwhjnDmY4S8mFqdoKpx6m5riiE0iYQyDs34lPQh5Mg3MMozZU9arR7LHrqKPw54U0KxmHrwsd8TspI9LgBBAaeQeP5z1B1424aFr4G1sgHnip3AH/IIDsx8kHYYdX447dHk5fibPn/pXoquHBMOkP6udixdy/VJKAPmEEgey7+nLMAOGNYKt6gwVf76o5os7Y5QG1zkLyUyE95CXEyCCUNwURpyUugNRaixw9s+bkSaALAM/WnXTK13BEyHd3DaJ5KAm1MR/dIikLT2X+Gj2/BN+oK2vWRVhTqF7yOaY0Nn1u2RD5AHlRcH84T2xVB+HCH77q0JA3mlxeOwvfvBqrMBPqn9Kdh1KHp91MHJJDgsPDmlnJOG5KCoiiUNfp4Y3M5Tls4Gfyk7PZ9oRFCfIMlBj1hUEtJQ7WxqFXSjeYpP8G278Nw3oQeQoJwD6IE3Cih5jano3sq0+ai8bynTug5RlxmF/WmtU2l4cpPg/t17Tfew4MwwJScZJqS/Oz1pjIoufUXAIumctWkATy2fB/Pri7mikkDuPO/29lS1oSqwLB+ToandfxctBAnOz15OFrtThRvDVpjUasjRYGcMwnknBnF3h1JgnAP0nI8ydlLRsI93Bd7ahiZ5iK1HSUKO+Pw6eiDEow6Rg0ei9t6ZKmza6Zks73CzRMr9lFU72VLWRMj01xsr3Bz4ZiOJRARQoSFUkZg2/cRruX3AQa+EZdEuUfHJmvCPcihM8K9Y024J6vxBNhS1sScwSld/lqmzYVhdbWMhDFN1OZqzNjUNq9XFIXbTh+Mqigs3VzOuSP788Ql4/jRnFwu7GAWLyFEmJ48HMXUcexagveU61o2a/VUMhLuQdSmUuDQ9KbouM/31GBCtwRhAMOVgbVsdfh8os+PYgSPuayQFmfnxhmDeH9HFT87YwixNk2qIwkRAcH0SeixafiHzscz7Y5od+e4JAj3IFp9AaaioicMPP7F4qhM0+S1jWXkpcQytIvXgw9qnvQj4j+8mYR3rkOZdTPAcdf2F0/OlsArRIQZcZnUfndttLvRbhKEexCtYS9GXHaXpps8GWwsaWRnpZtfnD2025Je+IctoCnYjGv5vSgvfAYcPwgLIYSsCUeRVr0Na8lXh/5et6elJqboGF9Q5/fL8klwWDhvZPducPONvpLGcx5v+Xtbmc+EEOJwEoS7k2ng/OpBHJuegYCHhHeuI3Hpxbg++RmYJpb6AkIRLBZ9Mnriy/3sqvJw33nDiWljZ3JXCww6dPzBiGl7Y5YQGNSMOQAAIABJREFUQhwk09HdSG0sJHZdeKQUu/EptKYiAlnTidn2fHhHX6gZPXFwlHvZe4UMk7e3VXDWsH7MyuueDVlHUDX0c/+IseH5llR5QghxNDIS7kYHs7j4RlwSTqcWm0bDBc8STB2Da/m9AC1FDMSJW1tYT703yLwR0V2LNU79LvXfeaNL880KIfoGGQl3I+1AEHbP/iWhlBHoCTlgcdB0zqMkP38aAHqSjIQ7whfUeWl9CU6bxvTc5Gh3Rwgh2kWCcDey1OxAd2Vh2uLwjr+h5XE9aQjV121Gq8vHcHVPSse+pLY5wP++spn8ag83zBiE3SITPEKI3kGCcDey1O4ilDyszZ+ZjiRCGZO7uUe9X8gw+dFrWyiq9/LIwjHMlFGwEKIXkSFDdzFCaHX5rSp6iM57b3sFOyvd3HvucAnAQoheR0bC3cS+8zUUI0AoZVS0u9LrFdd7eW97JZqq8NrGMob3d3HWMDkOJITofSQId7WAB9fye3DseJXAgFn4h1wQ7R71ap/vqeHnb20jqJsAZMTb+ekZg7stM5YQQkSSBOEuFrPteWK2v4R39GI8M+4ErWvL6vVlVW4/97+3k7wUJw99ezROu4bTJh9hIUTvJf+CdTFr2Sr0+IG4T/tNtLvS672wtgRPQOeBb42gf5zk1xZC9H6yMasrmSbWstUEZddzRKwpqmdsZjw5ybHR7ooQQkSEBOEupDXsRfVWSxCOgCZfiJ2VbiZlSypIIUTfIdPRXUD1VEDIi7V0FQDBjClR7lHv9fL6EhIcVmJsGoYJp2YnRrtLQggRMRKEI8ix6R/oSYNxrnoItamYUOpodGc6etKQaHetV/p4VxW/X7YHTYHhaXHYLSpjMuKj3S0hhIgYCcIRogSacH35S0xLDGqgCQDNU07zuO+BIrP+J2pHRRO/en8XI9NcNHiD7Kp089Mzh0hKSiFEnyJBOEKsxV+iGCGUQBOmJRbT6kT1VuEfMj/aXet1yhp9/Pj1LcQ7LPzhotEoCniDBgOTYqLdNSGEiCgJwhFi2/8JhtWF95RrMWOSwTSwF7xHKG1itLvWq3iDOj9ZupWAbvC3S8bJUSQhRJ8mQTgSTBNb4acEs2fRPO1nLQ8fXinpZOAP6gR1A6vWsSlj0zS5/72d5Fd5eHjhGHJS5CiSEKJvkwW2SKjfj+YuIZA9J9o96RbbK5r4zjOr+Wpfbctjpmmy+B+rueedHQBsKG7gj5/sIWSY7W531f56PtpVzf/OzpViDEKIk4IE4QhQClcAEMycFuWedI+3tlRQWOfltiVbya/yALCtvIn1RfV8tqeG0gYfv/jvdl5cV8JL60owTZOKJj+meeyA/Gl+NQ6LyqUTpKayEOLkIEE4AtTCFRiOZPSkodHuSpczTZMv9tQwPisewzRZtrsKgCWbylEVCOomN760kTpvkJFpLh5bvpdF/1jDBU9+zUvrS4/Z7ud7apiWk4TDqnXX2xFCiKiSIBwBStFXBDOnwElQyWd3lYfyJj/zR6czOj2Or/bVUd8c5L0dlSyckEV/l43yJj8/mpPLQwvGcNGYdLISHIxOj+PRL/ZSXO9t1d7za4v51t9Wcvc7O6h0B5gzOCVK70wIIbqfbMzqJLWxEKVuL8HR10S7KxGXX+UhLc5OnOPQx+T1TWVoCszMS6a8ycdTXxXy9NeF+EMG187I4dTMeMoafVw+MQtFUbjjrPDsQGWTn4XPrOaFtSX89MwhfJZfgycQ4t+riwnpBssLahmXGc/cIRKEhRAnDwnCneTY+ToA/rzzotyTyArqBte+sJ55I/pz1znDAMiv9rBkUxkXj88kxWljek4yf/+qkBfXlTArL5mhaXH0s7c9ldw/zs7svGQ+2FnFrafl8efPCyisC4+KH1k4RjZiCSFOShKEO8M0se98FWPQbIy4rGj3JqIKqpvxBg0+31PDL0wTf8jg7rd3EGe38L3pgwAYkxHHraflUdsc5MIx6cdt89yRaXy0q5r3d1RRWOfFZdfISohhek5SV78dIYTokSQId5RpErv6ISwN+wjNvj3avYm47RXh1Ju1zUG2lzfx1tYKCmo8/GnhGBJjrAAoisIVpw5od5szcpNIcFj48+cFADz07TGMyYhDPQnW0oUQoi2yMauDrIWf4lz9ML4RF2OOvSTa3Ym47RVuYqwqqgIvri/ljc3lLDwlg2k5HZ82tmoqF4xOp7Y5iKYqjExzdTixhxBC9AXyL2AHWctWYaoWmuY+CGrfm1DYXtHE6Ix4zh7ej/e2V2KaJldNbv+o92gWjssAYER/lxxFEkKc9Ppe9Ogm1ooNhJJHgKXvFRUIhAzyqz1cPjGLm2bmkBhjJcFhJSuh8+91YFIM107NJjfFGYGeCiFE7yZBuCNMA0vVpj5bIWl9cQNB3WR8VgJWTeX2MyJbD/n7s3Ij2p4QQvRWMh3dAVrDPlR/A6H+46LdlS6xfG8tdovK5IGJ0e6KEEL0aRKEO8BSsQGAYB8MwqZpsryghlOzE2TNVgghupgE4Q6wVG7AtMSgJw+LdlcirrjeR3G9j5m5krlKCCG6mgThDrBWbiTUb2yf3BW9qbQRgInZCVHuiRBC9H0ShE+UHsRStYVg//HR7kmX2FzWiNOmkZscG+2uCCFEnydB+GgMnbgP/hdryVetHrbU7kTR/YTS+t56MMCWsiZGp8ehqZLFSgghupoE4aPQanfi2P0GzuW/RPE3QsgHhNeDgT45EvYGdfKr3IzJjI92V4QQ4qTQ9xY1I8Ravi78Z/UWUv4xAcOZRuM5j2Mt/RojJhUjfmCUexh5XxbUopswNiMu2l0RQoiTggTho7BWrMVwJKO7MjBjUtHqdhP//vdRQj4CA2ZBHys6UOMJ8P8+zmdoPydTBkpVIyGE6A4ShI/CUr6WYPokGr/1DAD2XUuJ//CHAASy50SzaxEV1A0avEF+/eFuPIEQj59/CjaLrFIIIUR3kCD8TQdqBFvqC/CNOFQdyZ93LoY9AdXfQDB7dhQ7GFm/fG8n7++oAuC20wczJFVyOgshRHeRIPwN1uLlxH98K8HU0fiHLzz0A4sD77jrsVSsw3BlRK+DEXLfezspqfeyoaSR04akMDo9jksnZEa7W0IIcVI5qYKw4m8k6cWzcM++n0DeuW1eYytejqlaqF+4FKytqwY1T76lO7oZMWWNPt7bXsnVk7NbjhxVu/00+kO8vbUCgP4uG/efP4IYSVEphBDd7qQKwtayVWjuUmK2PksobTyGNQ7FCKCEfOHRraFjLVsdzoZl7f0lCl9cV8Lza0tIiLGy8JQMajwBFj6zGtMETVX4z+KJJMZYJQALIUSUnFxBuHRl+M+i5SQ9fzpGbD+UkBcMA++47xG74W8o/ka8p3w3yj2NjBV7awF4Yvk+Th+SwpJNZXiDBlZN4cyhqQyW9V8hhIiqkysIl6xEd6aheSowFRXVUwmYqEEPrq9+3XJdMHNq9DoZISUNXvbVepk/Oo0Pdlbxw1c3U+0JMC0nibvPGUac46T6Xy+EED3SyfMvccCDpWozzRN/AJZYAlnTMJzpoGrEfXgz1rLVuOc+iD3/bYJZ06Pd205bsbcOgGumZDN3SCr3vruDOLuFG2cMon+cPcq9E0IIASdRELYVfYpi6gSzZhLMntXqZ01nPoJWX0Bw4Fx8o6+KUg8ja8XeWrISHAxMimFQcizLfjgDtY8lGBFCiN7upAnCjh2vojvT2hzlGvHZGPHZUehV1/CHDNYU1jN/TDrKgcArAVgIIXqePhuEqz0B3t5agcuusWioDVvhJ3jHXQ9q9+wE3lDcwL9XF+GyW7j1tDySYm1d/pr5VR40VaGyyY8vZDAjV9JPCiFET9Zng/Cdb21jfUm4QP0c9y5SjRDlA+dTVeMhNzm2ZYTYFbxBnbve3k7IMPEEdLaWN/HsVROJtUXuC4Bpmuyq8jCsnxNFUSiq83LtC+vxBg3iHRZsmsKk7MSIvZ4QQojI65NBeGt5E+tLGrlxxiBeXl9K0/YPaXakc/Yr9ejGWq6ePICb5+S1u73NpY2oqsLo9ONXF/IFdX7/cT6V7gBPXTaOJn+IW5ds5Ys9Ncwb2b8zb6uVl9eX8odP9vDzs4awuayJ1fvrsKgq108fQHG9j/FZ8Tjk/K8QQvRofSYIv7WlnP4uO5MHJfLPrwtx2jQum5hFjGowcvU63jKnMzAplqGpTp5dXcycwSmMy0o4brtvb63g/vd3Ypgwor+L04amcNnELJy2I2+daZr8+PUtrCtuYPGkAYzLSsAwTVKcNj7Jr45YEK5vDvK3FfsB+N1H+ZjAtJwkrpo0gKmDZApaCCF6i14dhP0hg1c3lDI6PY77398FwNB+TnZXefj+zBxcdguLs8qJX+NlvXUS9583nOykGLaUNXLfezt5/upTj5otan9tM5qq8MAHu5iYncjsvGQ+2V3NE1/uZ8mmcp6+fDz9XTbqvUESE2MBeH9HFeuKG/jZmUO4eHw4D7OqKJw2JIW3t1bgC+oRGZ3+bcU+mgMhfjw3jz99VsDlE7O47fTBnW5XCCFE9+rVQfj97ZU88lkBCQ4LVk3hB7Ny+evyvQxJdbJ48gAAYoo+w1Qt3P4//4NpD08n33PucG56eRP/XlXEjTNzWtrzhwze3lrOFwW1LC+oJc5uQVMVfnnucPrH2bni1AFsLGngR69t4foXN2DVVArrvPzf+SOYkZ3AI58VMDLNxXfGtS7wcPbwfry2sYzffpzP3ecMa8nj3BH51R5e31TGonGZXDVpANNzkshJju1we0IIIaKnVwfhj3aFS/A1+EKcMTSVqyYN4MxhqcRYNKxauCautfBTgumnYtrjW553anYig1Njya/2tGrv8eV7eX5tCfEOC/NHp/H2tgqunpzdKrnFuKwEfnfhSP7+VSHxDgupThsPvruDVKeN5kCIe84de8RxoFOzE7lh+iCe/Go/Hn+oUwUT3t1Wiaoo3DBjEICknhRCiF6s1wbhBm+QVYX1zBvRj11VHi6bmAVARryj5RrFU4m1egvuaT8/4vnJsTZqm4Mtfy+s8/Ly+lIuGpPOXecMRVEUfjA7l+RY6xHPnZaTzLScZAA8gRCPfrmfktpmrjg166j1eK+fMQiXw8Ijn+7h4U/3cOfZwzr0vndVuclLiSUh5sh+CSGE6F16ZRBeW1TPHW9uQzdMrpw0gJFpbe9athV9BkBw4GlH/Cw51srW8qaWv7+7rQLDNLlpVk7L8aVU5/HP9jptFn6zYCz19c3HvfbyiVmUN/p4YW0JF43NaNdu62/aXeVhWo5svhJCiL5AjXYHOuKplYXYLSqPLhp71AAMYC1fh2GLJ5Q66oifJcfaqDtsJJxf7SE7MaZdgbczrp8+iMQYK//8uvCEn1vbHKDGE2BYP5mCFkKIvqDXjIQN0+Tr/XUU1/tYU1jP92fmHPU4jm3P2yghH1rdLvTkYaAc+V0jKdaKJ6C37FguqGnulvVVl93CBaPTeH5dCdWewAkF/d2V4TXsoRKEhRCiT+gVQdg0TX72xjY+21MDgKrABaPTjnq9a8WDEPKiGEH8eee1eU3KgTSSdd4gSUBxvZdzhveLeN/bcuGYdJ5dU8xPlm7l3JH9ufzAerZhmsfM8byryg3A0H6ubumnEEKIrtUrgvCKfXV8tqeGa6dmMzE7EV/QaLMcn+qpQPE3oDXub3lMT257A1TSgQ1XtZ4Ajd4Qhtl9O41zUmI5b2R/1hTV89Aneyiu81Le5GdjSQNPXjaOvJS2+7GptJGMeDuJsilLCCH6hB4RhKvcfjwBvc3zrqZp8tgXe8lOdPC96YNajh4dQfeT9OLZYOqtHg4dJQgnH5gGrm0O0uQPAZCX2n3nbe8/fwS6YXL3Ozt4eUMpTpuGRVX4xVvbefaqidgsrd9nSDdYXVjPOSO6Z7QuhBCi60V9Y9ayXVVc/I813PDiRgzTBEDx1RH79e9RPJXsqvSwu8rDlZMGHD0AA7b9n6D6alH9DeiuLAx7uHjB0UbCB48e1TYH2FnpxqIqDEyMifC7OzZNVXjwgpF88sMZfPD96fzi7KEU1DSzrrj+iGs3lTXiCegtR6OEEEL0flENwtVuP/e/vwtVUajzBimobkYJuEl443Kca/5E3LKf8M62ciyqwlnDjhwBavUFpDw1Bmvhp9h3v4HhSMY3/Dt4T/kuwYwpGPYEjNi2146TDkzpVrkDfLSziqmDkrAcI8h3JZfdgs2iMnVQEgqwpazpiGtW7qtDU2DKQKmMJIQQfUVUp6MfW76PgG7w0LdHc/NrW1hf0sDo2pVYq7fgG3wBjj3/xadOZlbemW0mp7AWL0f115P41lWYqg3fqMtwz30QgEDuOahNpXCUjU4Oq4bTpvHu9koq3QF+ckZ6l77X9nDZLeSkxLY6v3zQptJGRqTF4bL3iBUEIYQQERC1kfC+mmbe2VbBpROymDooif4uG+uLG7BUb8XU7DSd9TAmCgMD+Zw3qu3RrKVmBwCmZicwcC6eybe2/ExPzCOYPeuYffCHDArrvCTHWpmd1zOmeUenx7GlrAnzwNT8QXtrmslLkRzRQgjRl3T7sOq8J1YycUACVZ4AdovKNZOzURSFCQMSWFvUgBHYQok1B7dfw6YlMdCsY0pu2wHSUr2VQMZUGi56EbQT3zE8Ky+ZT/Nr+N38Ucdcb+5OYzLi+O/WCkoafAw4sEbd6AtS2xwkV4KwEEL0KRENwuvWreOll14C4K677iI+Pv6Ia3TD5IuCGnxBgx/PzSPxwAapWXkpvL+jEr18M8uDE3n6tc38MZTEKGcTdksbAdI0sFRvxzvy0g4FYIBff2skqqpg6URVo0g7mMpyW3lTSxDeWxNOiSlBWAgh+paIDv9efvll7r//fhYtWsQ777zT5jV/+c4Yvp6xgVX/k8GVkwa0PH7G0FSGxbhJMBupjB3CnmoPblt/BlmP3CkMoDXsQwk1o7eRkrK9bBa1RwVggLwUJ5qqsKvqUIWnfbXhICwlC4UQom+JaBDWdR273U6/fv2oqqpq85rR5m7iv/4tcav/2Opxm0Xl2txGAGZPm8NHP5jB+BEjsTeXt9mOpWwNAKHU0RF8B9Fns6jkpcSyq9Ld8lhBTTN2i9qqQpQQQojeL6JBOCYmhkAgQFVVFampqW1e41z5GwDsez9A8dW1+tn5SaWYqGQPn0ycw4LhykANulEC39gtbBrEbvgboeThhPqNieRb6BGG9Xe1jISfXV3ERzurGJQUg9bDRu1CCCE6p91BeOPGjSxevBgAwzC45557uPTSS1m8eDH794fTRF5yySXcc889vPjii1x44YVttmMr+Ypg6hgUI0DKPybi+uzOlp85Ktagp4zAtIXXRQ1XRriT7jIALFWbsRZ+iq3gPSy1O2k+9eY2izP0dsP6OanxBChr9PH48n0AXDQ2I7qdEkIIEXHt2pj197//nTfffJOYmPBGoY8++ohAIMBLL73Ehg0b+O1vf8tf//pXxowZw29/+9tjthUYMBvPjLtwbP0PtqLPse9+A/fs+8OdqViHf/iilmt1VyYAqrsUPXkYrk/uwFK3m1DycPS4AfiHzO/Qm+7phvcPF2h4a0s5IcPkp2cM4bShbc8sCCGE6L3aFYQHDhzIX/7yF372s58BsHbtWmbPng3A+PHj2bJlS7tfUL/ydVwWDYZOwdy2BG3JdSQ1b8e0xKAGPVgHzyQx8eAGpDwAXEYNplGGtWoTANbKDehz7yQx+ei1hLuTpqmH9bnzpjhsWDWFlzeEZwBmjOhPYlzPXw+O9H3oreQ+hMl9OETuRZjchyO1KwjPmzeP4uLilr+73W5crkPl9DRNIxQKYbEcvzm329/y30ryVFIUFf/W90C1YAUaEsZh1Id3A6PHk4pCoGQbZlURViCYOhpLzXbqcxYcui7KEhNjqY9wX+YMTuHjXdVkxNux6UbE2+8KXXEfeiO5D2FyHw6RexF2st6Hfv2OPmDs0Dlhl8uFx3PoCI1hGO0KwN9kOhIJZkwhdv0ToAfwDzoTIy7r0AWajUDOmTi2vxjOipU5laYzH8ZSu7tlvbivmj8mnY93VTMm48iz1kIIIfqGDu1qmjhxIp9//jkAGzZsYNiwtisVtUfTWX/CN2wB/qEX0jjviSN+3jzlJ6j+BlR/A+7Zv8KIH0gg58wOv15vMW1QErPzkjl3ZP9od0UIIUQX6dBI+Oyzz+bLL7/ksssuwzRNHnzwwQ53wIjLwn3GH47681C/sbhn3ouemNupxBy9jaYqPLSg7x2/EkIIcYhifrNSQBerqjqyQlBvd7Kuc3yT3IcwuQ9hch8OkXsRdrLeh2OtCfe9Q7ZCCCFELyFBWAghhIgSCcJCCCFElEgQFkIIIaJEgrAQQggRJRKEhRBCiCiRICyEEEJEiQRhIYQQIkokCAshhBBRIkFYCCGEiJJuT1sphBBCiDAZCQshhBBRIkFYCCGEiBIJwkIIIUSUSBA+jo0bN7J48WIAtm7dyqJFi7jiiiv41a9+hWEYAPzmN79h0aJFXHLJJaxduxaAoqIirrzySq644gpuv/12vF5v1N5DJLTnPjzwwAMsXLiQxYsXs3HjxlbPf+utt7j00ku7vd+R1tH7cLRre6NgMMhPf/pTrrjiChYtWsTHH3/M/v37ufzyy7niiiu49957W97fo48+yqJFi7jsssvYtGlTq3Z6+2eis/ehr3wmTuQ+AOzfv58LLrjgiHZWr17N3Llzu7PrPYMpjurJJ580L7jgAvPiiy82TdM0FyxYYK5du9Y0TdN86KGHzKVLl5rbt283L774YtMwDHPv3r3mggULTNM0zZtvvtl88803TdM0zZdfftl87LHHovMmIqA992HZsmXmtddea+q6btbU1LTcB9M0zW3btplXX311y/N7q87ch7au7a1effVV84EHHjBN0zRra2vNuXPnmjfeeKO5cuVK0zRN8+677zY/+OADc8uWLebixYtNwzDMkpISc+HChS1t9IXPRGfvQ1/5TLT3PpimaS5ZssRcsGCBOWPGjFZtlJaWmjfddNMRj58MZCR8DAMHDuQvf/lLy98rKiqYOHEiABMnTmTt2rX0798fh8NBIBDA7XZjsVgAyM/PZ86cOa2u7a3acx/y8/OZPXs2qqqSnJyMpmlUVVVRV1fHH/7wB+68885odT9iOnMf2rq2tzr33HP58Y9/3PJ3TdPYunUrU6ZMAWDOnDmsWLGCtWvXMmvWLBRFITMzE13Xqa2t7TOfic7eh77ymWjvfQBISEjgueeea/V8v9/Pvffey3333ddtfe5JJAgfw7x581qCKkB2djarVq0C4JNPPsHr9WKxWFBVlfPOO4/vfve7XHvttQCMHDmSZcuWAfDxxx/36uno9tyHkSNH8sUXXxAMBikqKiI/Px+v18tdd93FnXfeidPpjFb3I6Yz96Gta3srp9OJy+XC7Xbzox/9iFtuuQXTNFEUpeXnTU1NuN1uXC5Xq+fV19f3mc9EZ+5DU1NTn/lMtPc+AJx++unExsa2ev7999/PtddeS1paWrf3vSeQIHwCHnzwQf72t79xww03kJKSQlJSEkuXLiU1NZUPP/yQjz/+mEcffZSKigruuOMOli1bxnXXXYeqqiQlJUW7+xHT1n2YNWsWkyZN4pprruEf//gHo0ePpr6+nv3793Pfffdx2223kZ+fz69//etodz9i2nsfEhMT27y2NysrK+Pqq6/moosuYv78+ajqoX9KPB4P8fHxuFwuPB5Pq8fdbnef+kx09D7ExcX1qc9Ee+5DWyoqKlizZg2PPfYYixcvpqGhgVtvvbW7ut0zRHk6vMcrKipqWbd65plnzPLyctM0TfP+++83P/30U3PJkiXm3XffbZqmaYZCIXPBggXmnj17zCVLlpjbt283TdM0n376afO5556LzhuIkOPdh4KCAvOll14yTTO8vnPVVVcd9fm9WUfvQ1vX9lZVVVXmueeea65YsaLlsW+uAb799tvm5s2bzauvvtrUdd0sKSkx58+f36qd3v6Z6Ox96Cufifbeh8Mdbe33ZFwTthw/TIuDBg0axA033EBMTAxTp05l7ty56LrOunXruOyyy9B1nfnz55OXl0dTUxN33nknNpuNoUOHcs8990S7+xHT1n3w+/188cUXvPrqq9jt9j71fo/mRO5DW9f2Vk888QSNjY08/vjjPP744wDcddddPPDAAzz00EPk5eUxb948NE1j0qRJXHrppRiG0ec+E529D33lM9He+yDaJmkrhRBCiCiRNWEhhBAiSiQICyGEEFEiQVgIIYSIEgnCQgghRJRIEBZCCCGiRI4oCdHLff3119xyyy0MGTIE0zQJhUJcffXVnH/++W1eX1payo4dOzjjjDO6uadCiG+SICxEHzBt2jQefvhhIJyhaPHixeTm5jJy5Mgjrl25ciUFBQUShIXoASQIC9HHOJ1OLr30Ut555x2ee+45ysvLqaurY86cOdx88808+eST+Hw+JkyYwIABA3jggQcAWtJrxsXFRfkdCHHykDVhIfqglJQUtm3bxvjx43n66ad54YUXeOGFF9A0jRtuuIELLriAM888k7vvvpt7772XZ599ljlz5vDUU09Fu+tCnFRkJCxEH1RaWsqECRPYvHkzK1euxOVyEQgEjrhuz549/PKXvwTCxdlzc3O7u6tCnNQkCAvRx7jdbl555RUWLVqE1+vl/vvvZ//+/bz88suYpomqqhiGAUBubi6/+93vyMzMZO3atVRVVUW590KcXCQIC9EHrFy5ksWLF6OqKrquc/PNN5Obm8ttt93G2rVriYmJYdCgQVRWVjJs2DD++te/Mnr0aO677z7uuOMOdF0H6NVlBYXojaSAgxBCCBElsjFLCCGEiBIJwkIIIUSUSBAWQgghokSCsBBCCBElEoSFEEKIKJEgLIQQQkSJBGEhhBAiSiQICyGEEFHy/wHZLFI6PvKxAAAAAUlEQVS7dIsX7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fs = [\"Real Estate\",\"Commodities\"]\n",
    "erk.compound_returns(factors_assets[fs], start=1).plot(grid=True, figsize=(8,5), logy=True, title=\"Total returns of assets\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose Real Estate as the dependent variable and using the 5 factors as explanatory variables\n",
    "factors = factors_assets[factor_names].values\n",
    "assets  = factors_assets[asset_names].values\n",
    "y = factors_assets[\"Real Estate\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression (OLS) using analytical formula\n",
    "factors_ones = np.concatenate( (factors, np.ones((factors.shape[0],1))), axis=1 )\n",
    "betas = np.linalg.inv( factors_ones.T.dot(factors_ones) ).dot( factors_ones.T ).dot( y )\n",
    "betas = display_betas(betas, factor_names) \n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Regression (OLS) using statsmodels OLS method implemented in our kit\n",
    "lm = erk.linear_regression(y, factors)\n",
    "betas = display_betas(lm.params, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right, they coincide. We can also use the method **linear_regression_sk** which uses **scikit-learn** library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310261</td>\n",
       "      <td>1.212508</td>\n",
       "      <td>1.054238</td>\n",
       "      <td>0.287919</td>\n",
       "      <td>0.36184</td>\n",
       "      <td>-0.003587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310261       1.212508           1.054238              0.287919   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta              0.36184 -0.003587  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = linear_regression_sk(y, factors)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OLS Drawbacks \n",
    "\n",
    "OLS has major drawbacks. First, OLS has **no mechanism to filter out noise variables**. Second, it assumes that **factor loadings are constant over time**. In practice, you will generally have many variables that you would like to filter down.  Moreover, the assumption that the factor loadings are constant over time is restrictive, and not true.  In fact, we will show that factor loadings are highly dependent on the time period.\n",
    "\n",
    "To demonstrate how OLS can be susceptible to noise, we introduce **a noise variable positively correlated with the World Equities factor**. \n",
    "Then we re-run the OLS regression and we will see that the regression chosses to average the two signals, \n",
    "changing the loading on the World Equity factor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_plus_noise = factors_assets[factor_names].copy()\n",
    "factors_plus_noise_names = factor_names + [\"Noise\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndata = factors_assets.shape[0]\n",
    "noise = np.random.normal(loc=0, scale=2*factors_assets[\"World Equities\"].std(), size=ndata)\n",
    "noise = np.reshape( noise + factors_assets[\"World Equities\"].values, (ndata,1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors_plus_noise[\"Noise\"] = noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.332068</td>\n",
       "      <td>1.219228</td>\n",
       "      <td>1.054541</td>\n",
       "      <td>0.298805</td>\n",
       "      <td>0.37426</td>\n",
       "      <td>-0.019666</td>\n",
       "      <td>-0.003533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.332068       1.219228           1.054541              0.298805   \n",
       "\n",
       "      Currency Protection     Noise     alpha  \n",
       "beta              0.37426 -0.019666 -0.003533  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = linear_regression_sk(y, factors_plus_noise)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To demonstrate on the drawback of the OLS regression we show that **the OLS estimator depends greatly on the time period**. \n",
    "We pick different time periods and run the OLS regression and see that the factor loadings can change dramatically \n",
    "depending on the time period. \n",
    "\n",
    "We filter the data into two different regimes: a first **normal regime** will be months where US Equities had a positive monthly return and a second **crash regime** being the months where US Equities had a negative return. \n",
    "These are crude approximations, but even with this crude definition we will return substantially different factor loadings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.15022</td>\n",
       "      <td>1.30286</td>\n",
       "      <td>1.100558</td>\n",
       "      <td>0.210193</td>\n",
       "      <td>0.05183</td>\n",
       "      <td>0.00348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta         0.15022        1.30286           1.100558              0.210193   \n",
       "\n",
       "      Currency Protection    alpha  \n",
       "beta              0.05183  0.00348  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering data for positive US Equities - normal regime \n",
    "normal_data = factors_assets[factors_assets[\"US Equities\"] > 0].copy()\n",
    "normal_factors = normal_data[factor_names]\n",
    "normal_y = normal_data[asset_names][\"Real Estate\"]\n",
    "\n",
    "lm = linear_regression_sk(normal_y, normal_factors)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.365824</td>\n",
       "      <td>0.959781</td>\n",
       "      <td>0.792532</td>\n",
       "      <td>0.540801</td>\n",
       "      <td>0.588727</td>\n",
       "      <td>-0.011274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.365824       0.959781           0.792532              0.540801   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta             0.588727 -0.011274  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filtering data for negative US Equities - crash regime \n",
    "crash_data = factors_assets[factors_assets[\"US Equities\"] <= 0].copy()\n",
    "crash_factors = crash_data[factor_names]\n",
    "crash_y = crash_data[asset_names][\"Real Estate\"]\n",
    "\n",
    "lm = linear_regression_sk(crash_y, crash_factors)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with a crude definition of a **crash regime** we have isolated different factor loadings. \n",
    "Notice that during normal periods the loading on Currency Protection is close to zero, but during crash periods is **10x** larger."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For penalty methods, $\\lambda$ is an hyperparameter that we need to choose. Now, **scikit-learn does not use $\\lambda$**. It rather \n",
    "uses the parameter $\\alpha$ which can be related to $\\lambda$ via the following equation:\n",
    "$$\n",
    "\\alpha = \\frac{\\lambda}{2 n},\n",
    "$$\n",
    "where $n$ is the number of data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.349738</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.574002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.349738         0.5422           0.574002                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0  0.001834  "
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for now let's arbitrarily pick lambda = 0.1\n",
    "lambdapar = 0.1\n",
    "lm = lasso_regression_sk(y, factors, lambdapar=lambdapar)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us show how the Lasso regression filters out the noise variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.349738</td>\n",
       "      <td>0.5422</td>\n",
       "      <td>0.574002</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.349738         0.5422           0.574002                   0.0   \n",
       "\n",
       "      Currency Protection  Noise     alpha  \n",
       "beta                  0.0    0.0  0.001834  "
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm = lasso_regression_sk(y, factors_plus_noise, lambdapar=lambdapar)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.408359</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.127616</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.408359            0.0           0.127616                   0.0   \n",
       "\n",
       "      Currency Protection  Noise    alpha  \n",
       "beta                  0.0    0.0  0.00535  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# another try with lambda = 0.2\n",
    "lm = lasso_regression_sk(y, factors_plus_noise, lambdapar=0.2)\n",
    "betas = display_betas( np.append(lm.coef_, lm.intercept_), factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation\n",
    "In the experiments above with Lasso regression we had indeed another problem, the choice of $\\lambda$. \n",
    "In practice, most people use **cross-validation** to find out an optimal value. \n",
    "We will not give a formal definition of cross-validation here, and instead we will give a heuristic.\n",
    "\n",
    "In **cross-validation**, we first break the training set into $K$ folds, and define a list of $\\lambda$ values. \n",
    "For each fold, and for each $\\lambda$, we train the model $k-1$ other folds, and calculate the error on the test fold. At the end of this, you will have $K$ out of sample errors for each value of lambda. Then we pick the $\\lambda$ which produces the average error across \n",
    "the out of sample tests.\n",
    "\n",
    "Here we use cross validation to pick the optimal lambda value for Lasso regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lasso Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = cross_val_lasso_regression(y, factors, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.048634343434343426\n"
     ]
    }
   ],
   "source": [
    "best_lambda = recover_regression_bestpar_from_gsCV(gsCV, factors, \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.311805</td>\n",
       "      <td>0.875641</td>\n",
       "      <td>0.835079</td>\n",
       "      <td>0.044825</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000342</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.311805       0.875641           0.835079              0.044825   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.000342  "
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us run the cross-validation Lasso regression in the case of noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = cross_val_lasso_regression(y, factors_plus_noise, lambda_max=0.25, n_lambdas=100, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda: 0.05115141414141414\n"
     ]
    }
   ],
   "source": [
    "best_lambda = recover_regression_bestpar_from_gsCV(gsCV, factors, \"lasso\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.31354</td>\n",
       "      <td>0.85872</td>\n",
       "      <td>0.823262</td>\n",
       "      <td>0.033099</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000223</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta         0.31354        0.85872           0.823262              0.033099   \n",
       "\n",
       "      Currency Protection  Noise     alpha  \n",
       "beta                  0.0   -0.0 -0.000223  "
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elastic Net regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recall that the **Elastic Net regression** was: \n",
    "$$\n",
    "\\text{minimize} \\;\\; \\frac{1}{2N} \\bigl( ||\\mathbf{y} - X\\mathbf{\\beta} ||_2^2 + \\lambda_1||\\beta||_1 + \\lambda_2||\\beta||^2_2  \\bigr).\n",
    "$$\n",
    "However, the **ElasticNet** method implemented in scikit-learn defines the parameters $\\lambda_1$ and $\\lambda_2$ as:\n",
    "$$\n",
    "\\lambda_1 := \\alpha L^1_{ratio}\n",
    "\\quad\\text{and}\\quad\n",
    "\\lambda_2 := \\frac{1}{2}\\alpha \\left(1-L^1_{ratio}\\right),\n",
    "$$\n",
    "where $L^1_{ratio} \\in [0,1]$ for which if $L^1_{ratio}=1$ we are doing Lasso regression (hence, $\\alpha$ here is defined as the parameter in the Lasso regression) and when $L^1_{ratio}=0$ we do a Ridge Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "gsCV = cross_val_elasticnet_regression(y, factors, lambda_max=0.25, n_lambdas=50, l1_ratio_max=0.99, n_l1ratio=50, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda1: 0.04611379591836734\n",
      "best lambda2: 0.00023289795918367363\n"
     ]
    }
   ],
   "source": [
    "best_lambda1, best_lambda2 = recover_regression_bestpar_from_gsCV(gsCV, factors, \"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.310548</td>\n",
       "      <td>0.889796</td>\n",
       "      <td>0.844634</td>\n",
       "      <td>0.056504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.000444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.310548       0.889796           0.844634              0.056504   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.000444  "
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# The case with noise \n",
    "gsCV = cross_val_elasticnet_regression(y, factors_plus_noise, lambda_max=0.25, n_lambdas=50, l1_ratio_max=0.99, n_l1ratio=50, n_folds=10, rs=7777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best lambda1: 0.05114845102040816\n",
      "best lambda2: 0.00025832551020408184\n"
     ]
    }
   ],
   "source": [
    "best_lambda1, best_lambda2 = recover_regression_bestpar_from_gsCV(gsCV, factors, \"elasticnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.314048</td>\n",
       "      <td>0.855761</td>\n",
       "      <td>0.820833</td>\n",
       "      <td>0.033101</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.000206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.314048       0.855761           0.820833              0.033101   \n",
       "\n",
       "      Currency Protection  Noise     alpha  \n",
       "beta                  0.0   -0.0 -0.000206  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regression using the best estimator\n",
    "betas = np.append(gsCV.best_estimator_.coef_, gsCV.best_estimator_.intercept_)\n",
    "betas = display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Best Subset Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.453734</td>\n",
       "      <td>1.395798</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.001956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta             0.0       1.453734           1.395798                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.001956  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 2\n",
    "betas, alpha = best_subset_regression(y, factors, max_vars=2)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.274697</td>\n",
       "      <td>1.186262</td>\n",
       "      <td>1.091385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.274697       1.186262           1.091385                   0.0   \n",
       "\n",
       "      Currency Protection     alpha  \n",
       "beta                  0.0 -0.002295  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 3\n",
    "betas, alpha = best_subset_regression(y, factors, max_vars=3)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = display_betas(betas, factor_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>World Equities</th>\n",
       "      <th>US Treasuries</th>\n",
       "      <th>Bond Risk Premium</th>\n",
       "      <th>Inflation Protection</th>\n",
       "      <th>Currency Protection</th>\n",
       "      <th>Noise</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td>0.274694</td>\n",
       "      <td>1.186268</td>\n",
       "      <td>1.09139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.002295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      World Equities  US Treasuries  Bond Risk Premium  Inflation Protection  \\\n",
       "beta        0.274694       1.186268            1.09139                   0.0   \n",
       "\n",
       "      Currency Protection  Noise     alpha  \n",
       "beta                  0.0    0.0 -0.002295  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using max_vars = 3 and noisy data\n",
    "betas, alpha = best_subset_regression(y, factors_plus_noise, max_vars=3)\n",
    "\n",
    "# Regression using the best estimator\n",
    "betas = np.append(betas, alpha)\n",
    "betas = display_betas(betas, factors_plus_noise_names)\n",
    "betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regime Prediction with Machine Learning - Part 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our analysis we will use a large macroeconomic database from **FRED St. Louis** designed by **McCracken and Ng (2015)**. \n",
    "It involves **129 macroeconomic monthly time series over the period 1959-2018**. \n",
    "The data is organized into **8 categories**:\n",
    "1. Output and income\n",
    "2. Labor market\n",
    "3. Housing\n",
    "4. Consumption, orders and inventories \n",
    "5. Money and credit\n",
    "6. Interest and exchange rates\n",
    "7. Prices\n",
    "8. Stock market. \n",
    "\n",
    "Detail description of the variables under each category can be \n",
    "found __[here]( https://s3.amazonaws.com/files.fred.stlouisfed.org/fred-md/Appendix_Tables_Update.pdf)__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>IPDCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DSERRG3M086SBEA</th>\n",
       "      <th>CES0600000008</th>\n",
       "      <th>CES2000000008</th>\n",
       "      <th>CES3000000008</th>\n",
       "      <th>UMCSENTx</th>\n",
       "      <th>MZMSL</th>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <th>INVEST</th>\n",
       "      <th>VXOCLSx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1/1/59</th>\n",
       "      <td>2437.296</td>\n",
       "      <td>2288.8</td>\n",
       "      <td>17.302</td>\n",
       "      <td>292258.8329</td>\n",
       "      <td>18235.77392</td>\n",
       "      <td>22.6248</td>\n",
       "      <td>23.4555</td>\n",
       "      <td>22.1893</td>\n",
       "      <td>32.4027</td>\n",
       "      <td>21.9673</td>\n",
       "      <td>...</td>\n",
       "      <td>11.358</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.9</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>84.2043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2/1/59</th>\n",
       "      <td>2446.902</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>17.482</td>\n",
       "      <td>294429.5453</td>\n",
       "      <td>18369.56308</td>\n",
       "      <td>23.0679</td>\n",
       "      <td>23.7720</td>\n",
       "      <td>22.3816</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>22.0826</td>\n",
       "      <td>...</td>\n",
       "      <td>11.375</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>83.5280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3/1/59</th>\n",
       "      <td>2462.689</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>17.647</td>\n",
       "      <td>293425.3813</td>\n",
       "      <td>18523.05762</td>\n",
       "      <td>23.4002</td>\n",
       "      <td>23.9159</td>\n",
       "      <td>22.4914</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>22.5150</td>\n",
       "      <td>...</td>\n",
       "      <td>11.395</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.4</td>\n",
       "      <td>6508.0</td>\n",
       "      <td>12349.0</td>\n",
       "      <td>81.6405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4/1/59</th>\n",
       "      <td>2478.744</td>\n",
       "      <td>2330.3</td>\n",
       "      <td>17.584</td>\n",
       "      <td>299331.6505</td>\n",
       "      <td>18534.46600</td>\n",
       "      <td>23.8987</td>\n",
       "      <td>24.2613</td>\n",
       "      <td>22.8210</td>\n",
       "      <td>33.1553</td>\n",
       "      <td>22.6592</td>\n",
       "      <td>...</td>\n",
       "      <td>11.436</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.1</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>81.8099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5/1/59</th>\n",
       "      <td>2493.228</td>\n",
       "      <td>2345.8</td>\n",
       "      <td>17.796</td>\n",
       "      <td>301372.9597</td>\n",
       "      <td>18679.66354</td>\n",
       "      <td>24.2587</td>\n",
       "      <td>24.4628</td>\n",
       "      <td>23.0407</td>\n",
       "      <td>33.3137</td>\n",
       "      <td>23.1204</td>\n",
       "      <td>...</td>\n",
       "      <td>11.454</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>95.3</td>\n",
       "      <td>280.1</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>12646.0</td>\n",
       "      <td>80.7315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             RPI  W875RX1  DPCERA3M086SBEA    CMRMTSPLx      RETAILx   INDPRO  \\\n",
       "Date                                                                            \n",
       "1/1/59  2437.296   2288.8           17.302  292258.8329  18235.77392  22.6248   \n",
       "2/1/59  2446.902   2297.0           17.482  294429.5453  18369.56308  23.0679   \n",
       "3/1/59  2462.689   2314.0           17.647  293425.3813  18523.05762  23.4002   \n",
       "4/1/59  2478.744   2330.3           17.584  299331.6505  18534.46600  23.8987   \n",
       "5/1/59  2493.228   2345.8           17.796  301372.9597  18679.66354  24.2587   \n",
       "\n",
       "        IPFPNSS  IPFINAL  IPCONGD  IPDCONGD  ...  DSERRG3M086SBEA  \\\n",
       "Date                                         ...                    \n",
       "1/1/59  23.4555  22.1893  32.4027   21.9673  ...           11.358   \n",
       "2/1/59  23.7720  22.3816  32.6404   22.0826  ...           11.375   \n",
       "3/1/59  23.9159  22.4914  32.6404   22.5150  ...           11.395   \n",
       "4/1/59  24.2613  22.8210  33.1553   22.6592  ...           11.436   \n",
       "5/1/59  24.4628  23.0407  33.3137   23.1204  ...           11.454   \n",
       "\n",
       "        CES0600000008  CES2000000008  CES3000000008  UMCSENTx  MZMSL  \\\n",
       "Date                                                                   \n",
       "1/1/59           2.13           2.45           2.04       NaN  274.9   \n",
       "2/1/59           2.14           2.46           2.05       NaN  276.0   \n",
       "3/1/59           2.15           2.45           2.07       NaN  277.4   \n",
       "4/1/59           2.16           2.47           2.08       NaN  278.1   \n",
       "5/1/59           2.17           2.48           2.08      95.3  280.1   \n",
       "\n",
       "        DTCOLNVHFNM  DTCTHFNM   INVEST  VXOCLSx  \n",
       "Date                                             \n",
       "1/1/59       6476.0   12298.0  84.2043      NaN  \n",
       "2/1/59       6476.0   12298.0  83.5280      NaN  \n",
       "3/1/59       6508.0   12349.0  81.6405      NaN  \n",
       "4/1/59       6620.0   12484.0  81.8099      NaN  \n",
       "5/1/59       6753.0   12646.0  80.7315      NaN  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigmacro = pd.read_csv(\"data/Macroeconomic_Variables.csv\")\n",
    "bigmacro = bigmacro.rename(columns={'sasdate':'Date'})\n",
    "bigmacro = bigmacro.set_index(keys=\"Date\")\n",
    "bigmacro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>IPDCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DSERRG3M086SBEA</th>\n",
       "      <th>CES0600000008</th>\n",
       "      <th>CES2000000008</th>\n",
       "      <th>CES3000000008</th>\n",
       "      <th>UMCSENTx</th>\n",
       "      <th>MZMSL</th>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <th>INVEST</th>\n",
       "      <th>VXOCLSx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-01</th>\n",
       "      <td>2437.296</td>\n",
       "      <td>2288.8</td>\n",
       "      <td>17.302</td>\n",
       "      <td>292258.8329</td>\n",
       "      <td>18235.77392</td>\n",
       "      <td>22.6248</td>\n",
       "      <td>23.4555</td>\n",
       "      <td>22.1893</td>\n",
       "      <td>32.4027</td>\n",
       "      <td>21.9673</td>\n",
       "      <td>...</td>\n",
       "      <td>11.358</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.9</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>84.2043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-02</th>\n",
       "      <td>2446.902</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>17.482</td>\n",
       "      <td>294429.5453</td>\n",
       "      <td>18369.56308</td>\n",
       "      <td>23.0679</td>\n",
       "      <td>23.7720</td>\n",
       "      <td>22.3816</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>22.0826</td>\n",
       "      <td>...</td>\n",
       "      <td>11.375</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>83.5280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-03</th>\n",
       "      <td>2462.689</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>17.647</td>\n",
       "      <td>293425.3813</td>\n",
       "      <td>18523.05762</td>\n",
       "      <td>23.4002</td>\n",
       "      <td>23.9159</td>\n",
       "      <td>22.4914</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>22.5150</td>\n",
       "      <td>...</td>\n",
       "      <td>11.395</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.4</td>\n",
       "      <td>6508.0</td>\n",
       "      <td>12349.0</td>\n",
       "      <td>81.6405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-04</th>\n",
       "      <td>2478.744</td>\n",
       "      <td>2330.3</td>\n",
       "      <td>17.584</td>\n",
       "      <td>299331.6505</td>\n",
       "      <td>18534.46600</td>\n",
       "      <td>23.8987</td>\n",
       "      <td>24.2613</td>\n",
       "      <td>22.8210</td>\n",
       "      <td>33.1553</td>\n",
       "      <td>22.6592</td>\n",
       "      <td>...</td>\n",
       "      <td>11.436</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.1</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>81.8099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-05</th>\n",
       "      <td>2493.228</td>\n",
       "      <td>2345.8</td>\n",
       "      <td>17.796</td>\n",
       "      <td>301372.9597</td>\n",
       "      <td>18679.66354</td>\n",
       "      <td>24.2587</td>\n",
       "      <td>24.4628</td>\n",
       "      <td>23.0407</td>\n",
       "      <td>33.3137</td>\n",
       "      <td>23.1204</td>\n",
       "      <td>...</td>\n",
       "      <td>11.454</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>95.3</td>\n",
       "      <td>280.1</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>12646.0</td>\n",
       "      <td>80.7315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              RPI  W875RX1  DPCERA3M086SBEA    CMRMTSPLx      RETAILx  \\\n",
       "Date                                                                    \n",
       "1959-01  2437.296   2288.8           17.302  292258.8329  18235.77392   \n",
       "1959-02  2446.902   2297.0           17.482  294429.5453  18369.56308   \n",
       "1959-03  2462.689   2314.0           17.647  293425.3813  18523.05762   \n",
       "1959-04  2478.744   2330.3           17.584  299331.6505  18534.46600   \n",
       "1959-05  2493.228   2345.8           17.796  301372.9597  18679.66354   \n",
       "\n",
       "          INDPRO  IPFPNSS  IPFINAL  IPCONGD  IPDCONGD  ...  DSERRG3M086SBEA  \\\n",
       "Date                                                   ...                    \n",
       "1959-01  22.6248  23.4555  22.1893  32.4027   21.9673  ...           11.358   \n",
       "1959-02  23.0679  23.7720  22.3816  32.6404   22.0826  ...           11.375   \n",
       "1959-03  23.4002  23.9159  22.4914  32.6404   22.5150  ...           11.395   \n",
       "1959-04  23.8987  24.2613  22.8210  33.1553   22.6592  ...           11.436   \n",
       "1959-05  24.2587  24.4628  23.0407  33.3137   23.1204  ...           11.454   \n",
       "\n",
       "         CES0600000008  CES2000000008  CES3000000008  UMCSENTx  MZMSL  \\\n",
       "Date                                                                    \n",
       "1959-01           2.13           2.45           2.04       NaN  274.9   \n",
       "1959-02           2.14           2.46           2.05       NaN  276.0   \n",
       "1959-03           2.15           2.45           2.07       NaN  277.4   \n",
       "1959-04           2.16           2.47           2.08       NaN  278.1   \n",
       "1959-05           2.17           2.48           2.08      95.3  280.1   \n",
       "\n",
       "         DTCOLNVHFNM  DTCTHFNM   INVEST  VXOCLSx  \n",
       "Date                                              \n",
       "1959-01       6476.0   12298.0  84.2043      NaN  \n",
       "1959-02       6476.0   12298.0  83.5280      NaN  \n",
       "1959-03       6508.0   12349.0  81.6405      NaN  \n",
       "1959-04       6620.0   12484.0  81.8099      NaN  \n",
       "1959-05       6753.0   12646.0  80.7315      NaN  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually put the dates in datetime format. Note that directly using pd.to_datetime does not work fine \n",
    "# because up to 1968 (/68 in the index) year are parsed as years of the 21st century, i.g., 1/1/59 -> 2059-01.\n",
    "years  = np.arange(1959,2019+1,1)\n",
    "months = np.arange(1,12+1,1)\n",
    "strdate = []\n",
    "for y in years:\n",
    "    for m in months:\n",
    "        strdate.append( str(y) + \"-\" + str(m)  )\n",
    "        if y==2019 and m==1:\n",
    "            break\n",
    "# now parse dates\n",
    "bigmacro.index = pd.to_datetime(strdate, format=\"%Y-%m\", infer_datetime_format=True).to_period(\"M\") \n",
    "bigmacro.index.rename(\"Date\", inplace=True)\n",
    "bigmacro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(721, 128)"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigmacro.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consistent with the previous works in the literature, we use __[business cycle dating chronology provided by NBER](http://www.nber.org/cycles.html)__  which involves dates when recession began and ended in US economy. According to NBER's statistics we have **8 recession periods in our dataset** where duration is changing from 6 to 18 months. \n",
    "\n",
    "We represent regimes as **Normal and Recession** in our dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regime</th>\n",
       "      <th>RPI</th>\n",
       "      <th>W875RX1</th>\n",
       "      <th>DPCERA3M086SBEA</th>\n",
       "      <th>CMRMTSPLx</th>\n",
       "      <th>RETAILx</th>\n",
       "      <th>INDPRO</th>\n",
       "      <th>IPFPNSS</th>\n",
       "      <th>IPFINAL</th>\n",
       "      <th>IPCONGD</th>\n",
       "      <th>...</th>\n",
       "      <th>DSERRG3M086SBEA</th>\n",
       "      <th>CES0600000008</th>\n",
       "      <th>CES2000000008</th>\n",
       "      <th>CES3000000008</th>\n",
       "      <th>UMCSENTx</th>\n",
       "      <th>MZMSL</th>\n",
       "      <th>DTCOLNVHFNM</th>\n",
       "      <th>DTCTHFNM</th>\n",
       "      <th>INVEST</th>\n",
       "      <th>VXOCLSx</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-01</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2437.296</td>\n",
       "      <td>2288.8</td>\n",
       "      <td>17.302</td>\n",
       "      <td>292258.8329</td>\n",
       "      <td>18235.77392</td>\n",
       "      <td>22.6248</td>\n",
       "      <td>23.4555</td>\n",
       "      <td>22.1893</td>\n",
       "      <td>32.4027</td>\n",
       "      <td>...</td>\n",
       "      <td>11.358</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>274.9</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>84.2043</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-02</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2446.902</td>\n",
       "      <td>2297.0</td>\n",
       "      <td>17.482</td>\n",
       "      <td>294429.5453</td>\n",
       "      <td>18369.56308</td>\n",
       "      <td>23.0679</td>\n",
       "      <td>23.7720</td>\n",
       "      <td>22.3816</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>...</td>\n",
       "      <td>11.375</td>\n",
       "      <td>2.14</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>276.0</td>\n",
       "      <td>6476.0</td>\n",
       "      <td>12298.0</td>\n",
       "      <td>83.5280</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-03</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2462.689</td>\n",
       "      <td>2314.0</td>\n",
       "      <td>17.647</td>\n",
       "      <td>293425.3813</td>\n",
       "      <td>18523.05762</td>\n",
       "      <td>23.4002</td>\n",
       "      <td>23.9159</td>\n",
       "      <td>22.4914</td>\n",
       "      <td>32.6404</td>\n",
       "      <td>...</td>\n",
       "      <td>11.395</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.45</td>\n",
       "      <td>2.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277.4</td>\n",
       "      <td>6508.0</td>\n",
       "      <td>12349.0</td>\n",
       "      <td>81.6405</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-04</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2478.744</td>\n",
       "      <td>2330.3</td>\n",
       "      <td>17.584</td>\n",
       "      <td>299331.6505</td>\n",
       "      <td>18534.46600</td>\n",
       "      <td>23.8987</td>\n",
       "      <td>24.2613</td>\n",
       "      <td>22.8210</td>\n",
       "      <td>33.1553</td>\n",
       "      <td>...</td>\n",
       "      <td>11.436</td>\n",
       "      <td>2.16</td>\n",
       "      <td>2.47</td>\n",
       "      <td>2.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>278.1</td>\n",
       "      <td>6620.0</td>\n",
       "      <td>12484.0</td>\n",
       "      <td>81.8099</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-05</th>\n",
       "      <td>Normal</td>\n",
       "      <td>2493.228</td>\n",
       "      <td>2345.8</td>\n",
       "      <td>17.796</td>\n",
       "      <td>301372.9597</td>\n",
       "      <td>18679.66354</td>\n",
       "      <td>24.2587</td>\n",
       "      <td>24.4628</td>\n",
       "      <td>23.0407</td>\n",
       "      <td>33.3137</td>\n",
       "      <td>...</td>\n",
       "      <td>11.454</td>\n",
       "      <td>2.17</td>\n",
       "      <td>2.48</td>\n",
       "      <td>2.08</td>\n",
       "      <td>95.3</td>\n",
       "      <td>280.1</td>\n",
       "      <td>6753.0</td>\n",
       "      <td>12646.0</td>\n",
       "      <td>80.7315</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Regime       RPI  W875RX1  DPCERA3M086SBEA    CMRMTSPLx      RETAILx  \\\n",
       "Date                                                                            \n",
       "1959-01  Normal  2437.296   2288.8           17.302  292258.8329  18235.77392   \n",
       "1959-02  Normal  2446.902   2297.0           17.482  294429.5453  18369.56308   \n",
       "1959-03  Normal  2462.689   2314.0           17.647  293425.3813  18523.05762   \n",
       "1959-04  Normal  2478.744   2330.3           17.584  299331.6505  18534.46600   \n",
       "1959-05  Normal  2493.228   2345.8           17.796  301372.9597  18679.66354   \n",
       "\n",
       "          INDPRO  IPFPNSS  IPFINAL  IPCONGD  ...  DSERRG3M086SBEA  \\\n",
       "Date                                         ...                    \n",
       "1959-01  22.6248  23.4555  22.1893  32.4027  ...           11.358   \n",
       "1959-02  23.0679  23.7720  22.3816  32.6404  ...           11.375   \n",
       "1959-03  23.4002  23.9159  22.4914  32.6404  ...           11.395   \n",
       "1959-04  23.8987  24.2613  22.8210  33.1553  ...           11.436   \n",
       "1959-05  24.2587  24.4628  23.0407  33.3137  ...           11.454   \n",
       "\n",
       "         CES0600000008  CES2000000008  CES3000000008  UMCSENTx  MZMSL  \\\n",
       "Date                                                                    \n",
       "1959-01           2.13           2.45           2.04       NaN  274.9   \n",
       "1959-02           2.14           2.46           2.05       NaN  276.0   \n",
       "1959-03           2.15           2.45           2.07       NaN  277.4   \n",
       "1959-04           2.16           2.47           2.08       NaN  278.1   \n",
       "1959-05           2.17           2.48           2.08      95.3  280.1   \n",
       "\n",
       "         DTCOLNVHFNM  DTCTHFNM   INVEST  VXOCLSx  \n",
       "Date                                              \n",
       "1959-01       6476.0   12298.0  84.2043      NaN  \n",
       "1959-02       6476.0   12298.0  83.5280      NaN  \n",
       "1959-03       6508.0   12349.0  81.6405      NaN  \n",
       "1959-04       6620.0   12484.0  81.8099      NaN  \n",
       "1959-05       6753.0   12646.0  80.7315      NaN  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load regimes classifications\n",
    "recession_periods = pd.read_csv('data/Recession_Periods.csv')[\"Regime\"]\n",
    "# and insert them into bigmacro dataframe\n",
    "bigmacro.insert(loc=0, column=\"Regime\", value=recession_periods.values)\n",
    "bigmacro.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Normal       628\n",
       "Recession     93\n",
       "Name: Regime, dtype: int64"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigmacro[\"Regime\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a total of $628$ months of normal regimes and $93$ months of recession."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dates of normal and recession regimes\n",
    "normal_dates     = bigmacro[bigmacro[\"Regime\"] == \"Normal\"].index\n",
    "recessions_dates = bigmacro[bigmacro[\"Regime\"] == \"Recession\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find indices of recession regimes \n",
    "rec_idx = np.zeros_like(recessions_dates)\n",
    "rec_idx[0] = 1\n",
    "for i, date in enumerate(recessions_dates):\n",
    "    prev_date = date - 1\n",
    "    next_idx  = idx + 1\n",
    "    if prev_date not in recessions_dates:\n",
    "        rec_idx[i] = 1\n",
    "        rec_idx[i-1] = 1\n",
    "rec_idx = np.array([False if i==0 else True for i in rec_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeriodIndex(['1960-04', '1961-01', '1969-12', '1970-10', '1973-11', '1975-02',\n",
       "             '1980-01', '1980-06', '1981-07', '1982-10', '1990-07', '1991-02',\n",
       "             '2001-03', '2001-10', '2007-12', '2009-05'],\n",
       "            dtype='period[M]', name='Date', freq='M')"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recessions_dates[rec_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example using S&P500 regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1959-01-02</th>\n",
       "      <td>0</td>\n",
       "      <td>55.439999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-05</th>\n",
       "      <td>1</td>\n",
       "      <td>55.660000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-06</th>\n",
       "      <td>2</td>\n",
       "      <td>55.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-07</th>\n",
       "      <td>3</td>\n",
       "      <td>54.889999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959-01-08</th>\n",
       "      <td>4</td>\n",
       "      <td>55.400002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            idx  Adj Close\n",
       "Date                      \n",
       "1959-01-02    0  55.439999\n",
       "1959-01-05    1  55.660000\n",
       "1959-01-06    2  55.590000\n",
       "1959-01-07    3  54.889999\n",
       "1959-01-08    4  55.400002"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the S&P500 index for the current set of dates that we have \n",
    "startdate = dt.datetime(1959,1,1)\n",
    "enddate = dt.datetime(2019,1,1,) \n",
    "ticker = \"^GSPC\"\n",
    "\n",
    "sp500 = data.DataReader(ticker, data_source=\"yahoo\", start=startdate, end=enddate)\n",
    "sp500.insert(loc=0, column=\"idx\", value=np.arange(0,sp500.shape[0]))\n",
    "sp500 = sp500[[\"idx\",\"Adj Close\"]]\n",
    "sp500.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  316.,   505.,  2720.,  2932.,  3711.,  4027.,  5268.,  5373.,\n",
       "        5646.,  5963.,  7922.,  8071., 10616., 10760., 12314., 12669.])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S&P500 are daily data, then we have to find the right recession dates \n",
    "rr = []\n",
    "for date in recessions_dates[rec_idx]:\n",
    "    rr.append( sp500[str(date)].iloc[0,:][\"idx\"] ) \n",
    "rr = np.array(rr)\n",
    "rr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index of starting recession periods\n",
    "x1 = np.array(rr)[:-1:2]\n",
    "# index of ending recession periods\n",
    "x2 = np.array(rr)[1::2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,1,figsize=(12,6))\n",
    "ax.semilogy(sp500_ac.values, label=\"S&P500\")\n",
    "\n",
    "ax.axvspan(x1[0], x2[0], alpha=0.5, color='gray', label=\"recession\")\n",
    "for i in range(1,len(x1)):\n",
    "    ax.axvspan(x1[i], x2[i], alpha=0.5, color='gray')\n",
    "    \n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
